{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b51e95-4d54-4cac-8905-5e122b405880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b1c940ad-e5fb-4ef5-8443-1717301adbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class manipulates data from a csv file\n",
    "class ManipulateData:\n",
    "\n",
    "    #initialize file\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    #Reads the supplied file and shuffles the data\n",
    "    def filter_data(self):\n",
    "        data = pd.read_csv(self.file).dropna()\n",
    "        data = data.sample(frac = 1, random_state=30) #shuffling and ensuring everytime output is same shuffled data\n",
    "        return data\n",
    "\n",
    "    #Filter with respect to column passed as an argument \n",
    "    def seperate_columns(self, data, columns):\n",
    "        data = data[columns]\n",
    "        return data\n",
    "\n",
    "    #splits data to train and test data and returns train and test data as numpy array\n",
    "    #only training percentage is passed as an argument \n",
    "    def split_data(self, data, percent):\n",
    "        data_array = data.to_numpy()\n",
    "        train_size = math.floor(len(data_array)*percent) #takes integer as training size\n",
    "        #training and testing data are seperated as two numpy arrays inside tuple\n",
    "        train_data, test_data = data_array[:train_size,:], data_array[train_size:,:] \n",
    "\n",
    "        \n",
    "        train_length = train_data.shape[0]\n",
    "        test_length = test_data.shape[0]\n",
    "        print(f\"total training rows: {train_length}\\ntotal testing rows: {test_length}\")\n",
    "        \n",
    "        return train_data, test_data\n",
    "\n",
    "    #seperate features and target\n",
    "    def seperate_target(self, data):\n",
    "        rows = data.shape[0]\n",
    "        features = []\n",
    "        target = []\n",
    "        for row in range(rows):\n",
    "            features.append(data[row, :-1])\n",
    "            target.append(data[row, -1])\n",
    "        return np.array(features), np.array(target)\n",
    "\n",
    "    # scale features using mean normalization and returns numpy array\n",
    "    def scale_features(self, data):\n",
    "        # calculate mean, minimum, and maximum for each column of the features\n",
    "        feature_mean = np.mean(data, axis=0) #axis 0 refers to the column and axis 1 for row\n",
    "        feature_max = np.max(data, axis=0)\n",
    "        feature_min = np.min(data, axis=0)\n",
    "\n",
    "        scaled_data = []\n",
    "\n",
    "        # normalize and append each rows of features to new array \n",
    "        for row in data:\n",
    "            scaled_row = []\n",
    "            for i in range(len(row)):\n",
    "                scaled_value = (row[i] - feature_mean[i]) / (feature_max[i] - feature_min[i])\n",
    "                scaled_row.append(scaled_value)\n",
    "            scaled_data.append(scaled_row)\n",
    "\n",
    "        return np.array(scaled_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78f7920-450b-40c5-989c-72423342896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    # calculating cost using vectorization('np.dot()')\n",
    "    def calculate_cost(self, X_train, Y_train, th0, thj):\n",
    "            \n",
    "            m = X_train.shape[0]\n",
    "\n",
    "            # use vectorization to find dot product of two matrices (features and weights)\n",
    "            y_predict = th0 + np.dot(X_train, thj)\n",
    "        \n",
    "            sq_difference = (y_predict - Y_train) ** 2\n",
    "            total_cost = np.sum(sq_difference) / (2*m)\n",
    "        \n",
    "            return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1aaad438-a8f2-4318-a0d7-34cf16afc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class has all the methods required for gradient descent algorithm to work\n",
    "# Pass hyperparameters while creating object\n",
    "class LinearRegression(MSE):\n",
    "    def __init__(self, alpha, iterations):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "\n",
    "    #this method computes gradient using vectorization and utilizes the broadcasting power of numpy\n",
    "    def calculate_gradient(self, X_train, Y_train, th0, thj):\n",
    "        m = X_train.shape[0]\n",
    "        \n",
    "        y_predict = th0 + np.dot(X_train, thj) #get numpy array containing predicted y of each row\n",
    "\n",
    "        difference = y_predict - Y_train # subtract actual y (broadcasting is used to do matrix manipulation)\n",
    "        \n",
    "        gradient_th0 = np.sum(difference) / m #difference is an array of differences so we need to sum all and divide my number of rows\n",
    "\n",
    "        #vectorization used to find dot product and gets matrix with the same shape of weight\n",
    "        #broadcasting is utilized on difference and m\n",
    "        gradient_thj = np.dot(difference, X_train) / m \n",
    "\n",
    "        return gradient_th0, gradient_thj\n",
    "\n",
    "    #same as the calculate_gradient function but uses regularization \n",
    "    def calculate_regularized_gradient(self, X_train, Y_train, th0, thj, lam):\n",
    "        m = X_train.shape[0]\n",
    "        \n",
    "        y_predict = th0 + np.dot(X_train, thj)\n",
    "\n",
    "        difference = y_predict - Y_train\n",
    "        \n",
    "        gradient_th0 = np.sum(difference) / m\n",
    "        gradient_thj = np.dot(difference, X_train) / m\n",
    "\n",
    "        # regularization\n",
    "        gradient_thj += (lam / m) * thj\n",
    "\n",
    "        return gradient_th0, gradient_thj\n",
    "\n",
    "    # utilizes gradient descent formula  to get optimal weights and bias\n",
    "    def gradient_descent(self, X_train, Y_train, th0, thj):\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            gradients = self.calculate_gradient(X_train, Y_train, th0, thj)\n",
    "            th0 = th0 - (self.alpha * gradients[0])\n",
    "            thj = thj - (self.alpha * gradients[1])\n",
    "\n",
    "            # check cost over iteration\n",
    "            # if i%10 == 0 or i == self.iterations - 1:\n",
    "            #     current_cost = self.calculate_cost(X_train, Y_train, th0, thj)\n",
    "            #     print(f\"Iteration: {i}\\t Cost: {current_cost:.3f}\\t Bias: {th0:.3f}\\t Weight: {np.round(thj, 3)}\")\n",
    "            \n",
    "        return th0, thj\n",
    "\n",
    "    #same as gradient_descent but calls calls calculate_regularized_gradient method\n",
    "    def regularized_gradient_descent(self, X_train, Y_train, th0, thj, lam):\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            gradients = self.calculate_regularized_gradient(X_train, Y_train, th0, thj, lam)\n",
    "            th0 = th0 - (self.alpha * gradients[0])\n",
    "            thj = thj - (self.alpha * gradients[1])\n",
    "\n",
    "            if i%10 == 0 or i == self.iterations - 1:\n",
    "                current_cost = self.calculate_cost(X_train, Y_train, th0, thj)\n",
    "                print(f\"Iteration: {i}\\t Cost: {current_cost:.3f}\\t Bias: {th0:.3f}\\t Weight: {np.round(thj, 3)}\")\n",
    "            \n",
    "        return th0, thj\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c027cdb-3f19-4195-b51e-e373d48af10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and clear out null values\n",
    "file = 'Cancer_dataset.csv'\n",
    "\n",
    "df = ManipulateData(file)\n",
    "data = df.filter_data() #cleans out rows containing null values and shuffles the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5987d0c3-6d1d-43e2-864e-3eea156ac7c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02760f33-21c6-427d-a7b6-3908dc927860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "#first seperate columns by passing column names and after required columns are obtained from the data we split 80% of data as training data\n",
    "#index of the columns defined will be the same index on the array as well\n",
    "columns = ['mean_texture', 'tumor_size'] #the final column will be the target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "\n",
    "# now seperate features and target as two seperate arrays with each features index corresponding to target index\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19b1a57a-634b-496d-a944-f6236d7f5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 4.822\t Bias: 0.000\t Weight: [0.005]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12]\n",
      "\n",
      "\n",
      "final bias = 0.0067610733604299865 \t final weights = [0.11953371]\n"
     ]
    }
   ],
   "source": [
    "#initialize weight, biases and hyperparameters\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "\n",
    "#create object for linear regression class\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "\n",
    "# compute final weights and biases using gradient descent\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bdf5b-fdaa-4bab-8ff8-ef1781e0a580",
   "metadata": {},
   "source": [
    "##### Notice here: cost decreased over time and got stabalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a1247b5-52d4-4063-b77a-44d211655d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.638982284944249\n",
      "cost for test data = 3.5109876086243226\n"
     ]
    }
   ],
   "source": [
    "# Check mean squared error for both train and test\n",
    "mse = MSE()\n",
    "\n",
    "# calculate mean squared error using final predicted weights and bias\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5c58b-d02f-4f13-84cd-bd4503d7156d",
   "metadata": {},
   "source": [
    "From mean squared error function, we can observe that the cost is low on train data and higher on the test data \n",
    "which means it performs well on the training data but struggles to perform well on unseen data. \n",
    "So there may be problem of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901ff6b-6d23-4079-94d5-b89183401269",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17828d-fa8b-46b6-accf-7bd4b625c72c",
   "metadata": {},
   "source": [
    "Same pattern of code is used on this section as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c803a48-0cc6-429a-b8d4-0128d8a3dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_texture', 'lymph_node_status', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "212ec22b-a6ce-4670-a3bc-a76932a654c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 3.155\t Bias: 0.003\t Weight: [0.047]\n",
      "Iteration: 10\t Cost: 1.497\t Bias: 0.008\t Weight: [0.147]\n",
      "Iteration: 20\t Cost: 1.496\t Bias: 0.009\t Weight: [0.149]\n",
      "Iteration: 30\t Cost: 1.496\t Bias: 0.009\t Weight: [0.149]\n",
      "Iteration: 40\t Cost: 1.496\t Bias: 0.009\t Weight: [0.149]\n",
      "Iteration: 49\t Cost: 1.496\t Bias: 0.010\t Weight: [0.149]\n",
      "\n",
      "\n",
      "final bias = 0.00969690009063465 \t final weights = [0.14947094]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d32053e-bb87-478c-b8f6-f8cb37987332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.4961777208903009\n",
      "cost for test data = 2.918009092955125\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ca33c-0b0a-4cb0-ade0-066b43d2c746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35a54dfd-4bbf-4046-9ba3-f0e8bcb89659",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb58216-5166-4ffb-ba04-1c21275443fc",
   "metadata": {},
   "source": [
    "Same pattern of code is used throughout this with change in column array section. Calculation of BIC is additional part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ecdcc-1d08-4a42-825e-109128e30b6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a) Forward Stepwise Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a3aa1-3dac-4967-9d09-39cb7d6b8607",
   "metadata": {},
   "source": [
    "For the forward stepwise regression model I have choosen 5 of the random features. These features are: \n",
    "'mean_radius', 'mean_smoothness', 'mean_symmetry', 'mean_fractal_dimension', 'lymph_node_status'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df699a1-cdae-407e-a0ac-3bdae41cc37d",
   "metadata": {},
   "source": [
    "BIC= ln(n)k â€“ 2 ln(L) <br>\n",
    "$k$ is the number of parameters in the model.<br>\n",
    "$n$ is the number of data points.<br>\n",
    "$L$ is the likelihood of the model.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73c7b5d1-788d-44b5-b65d-ef15a171582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate BIC value\n",
    "def calculate_bic(k, n, mse):\n",
    "    ln_L = - (n/2) * (np.log(2 * np.pi * mse) + 1) # log likelihood equation\n",
    "    bic = (np.log(n) * k) - (2 * ln_L) # BIC equation\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940463bc-c111-45e4-99b6-372c9c0a4c05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2a19df7-7c42-4b4c-8081-54fcb4e6f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c738f-a971-4336-9ed9-9b6246722a2f",
   "metadata": {},
   "source": [
    "Now calculating BIC for bias only. \n",
    "To calculate the best bias for the model we need a bias that minimizes the cost. So the best bias would be the average value of the target values.\n",
    "Then calculate the MSE for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a27e8538-8c79-4353-bd2f-2504e4534fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579.6747148035079\n"
     ]
    }
   ],
   "source": [
    "k_base = 1\n",
    "n_base = target.shape[0]\n",
    "bias_base = np.mean(target)\n",
    "mn_sq_err = np.mean((bias_base - target) ** 2)\n",
    "bic_base = calculate_bic(k_base, n_base, mn_sq_err)\n",
    "print(bic_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d9e6a-f8ab-4212-acbb-026463da13a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0522cdd-6b01-4725-b4fb-bccdc35d7eac",
   "metadata": {},
   "source": [
    "Now adding each of the five features to formulate five separate univariate models, and calculate AIC for each of the five models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c8921ad-c6ac-4d10-914f-3045a8296a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b348424d-2c41-4393-be59-e177183d5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.822\t Bias: 0.000\t Weight: [0.005]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12]\n",
      "\n",
      "\n",
      "final bias = 0.0067610733604299865 \t final weights = [0.11953371]\n",
      "cost for train data = 1.638982284944249\n",
      "cost for test data = 3.5109876086243226\n",
      "BIC: 512.9935233150557\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "\n",
    "n = target.shape[0]\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e510fb3e-9286-4077-873e-e8a785cae397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 5.041\t Bias: 0.000\t Weight: [0.]\n",
      "Iteration: 10\t Cost: 5.034\t Bias: 0.003\t Weight: [0.]\n",
      "Iteration: 20\t Cost: 5.027\t Bias: 0.006\t Weight: [0.001]\n",
      "Iteration: 30\t Cost: 5.020\t Bias: 0.008\t Weight: [0.001]\n",
      "Iteration: 40\t Cost: 5.013\t Bias: 0.011\t Weight: [0.001]\n",
      "Iteration: 49\t Cost: 5.007\t Bias: 0.013\t Weight: [0.001]\n",
      "\n",
      "\n",
      "final bias = 0.013198331688692522 \t final weights = [0.0013406]\n",
      "cost for train data = 5.006975485591109\n",
      "cost for test data = 8.675776732462515\n",
      "BIC: 655.0162875239262\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "\n",
    "n = target.shape[0]\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00da266e-6281-443b-bb41-85a46c00d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 5.041\t Bias: 0.000\t Weight: [0.]\n",
      "Iteration: 10\t Cost: 5.034\t Bias: 0.003\t Weight: [0.001]\n",
      "Iteration: 20\t Cost: 5.027\t Bias: 0.006\t Weight: [0.001]\n",
      "Iteration: 30\t Cost: 5.020\t Bias: 0.008\t Weight: [0.002]\n",
      "Iteration: 40\t Cost: 5.013\t Bias: 0.011\t Weight: [0.002]\n",
      "Iteration: 49\t Cost: 5.006\t Bias: 0.013\t Weight: [0.002]\n",
      "\n",
      "\n",
      "final bias = 0.013197496381459216 \t final weights = [0.00248787]\n",
      "cost for train data = 5.006101518706459\n",
      "cost for test data = 8.674570800679586\n",
      "BIC: 654.9909755846408\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_symmetry', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "\n",
    "n = target.shape[0]\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4a3b82ca-c3d7-4928-ae7a-4efd1d721170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "final bias = 0.014399037919676063 \t final weights = [0.00089368]\n",
      "cost for train data = 5.921272362800858\n",
      "cost for test data = 5.0772145374047986\n",
      "BIC: 679.335588147148\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_fractal_dimension', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "\n",
    "n = target.shape[0]\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8cbe5370-e186-4cf5-b95d-8b06bcf4880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "final bias = 0.013937334816510107 \t final weights = [0.06105735]\n",
      "cost for train data = 5.1777714962668915\n",
      "cost for test data = 4.154766773645429\n",
      "BIC: 659.8799809551556\n"
     ]
    }
   ],
   "source": [
    "columns = ['lymph_node_status', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "\n",
    "n = target.shape[0]\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eadf30-e53f-4b2e-a613-28306a8b05c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9063432e-92c1-49bf-853f-daf1d17a74c9",
   "metadata": {},
   "source": [
    "Here, while calculating BIC for each univariate model, we can see that the minimum BIC which is less than the base BIC is obtained while adding 'mean_radius' feature. So I am going to go with teh 'mean_radius' feature for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c90af-9cfd-4b3e-aec9-2ea27a8ff16e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f7a42ad-063f-4e4b-9d93-7a2ef7d73acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6770ff2-2b3d-4b80-aa47-318f51b65eaa",
   "metadata": {},
   "source": [
    "Now we are left with 4 features ('mean_smoothness', 'mean_symmetry', 'mean_fractal_dimension', 'lymph_node_status') which we need to calculate the BIC with Bivariate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e006509-4186-47bc-b544-30f85dd2a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.822\t Bias: 0.000\t Weight: [0.005 0.   ]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045 0.   ]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073 0.   ]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094 0.001]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109 0.001]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12  0.001]\n",
      "\n",
      "\n",
      "final bias = 0.0067609394281968075 \t final weights = [0.11953144 0.00067867]\n",
      "cost for train data = 1.6389675433288369\n",
      "cost for test data = 3.5109416088152496\n",
      "BIC: 498.0620178980737\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "# print(features)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0bbb84a-1dad-4440-aaee-3517dba79a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.821\t Bias: 0.000\t Weight: [0.005 0.   ]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045 0.   ]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073 0.001]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094 0.001]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109 0.001]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12  0.001]\n",
      "\n",
      "\n",
      "final bias = 0.006760613049397101 \t final weights = [0.11952585 0.00124699]\n",
      "cost for train data = 1.6389380653684633\n",
      "cost for test data = 3.5108316988249233\n",
      "BIC: 498.05940994972826\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_symmetry', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1703fc55-a0de-4d56-a45c-314c60048a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.822\t Bias: 0.000\t Weight: [0.005 0.   ]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045 0.   ]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073 0.   ]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094 0.   ]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109 0.   ]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12 0.  ]\n",
      "\n",
      "\n",
      "final bias = 0.006761023110009425 \t final weights = [0.11953287 0.00041581]\n",
      "cost for train data = 1.638976519949763\n",
      "cost for test data = 3.510970270699966\n",
      "BIC: 498.0628120605177\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_fractal_dimension', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "259db1cb-93e1-46ea-80f4-77e4fae76cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01 ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033]\n",
      "\n",
      "\n",
      "final bias = 0.006614204030448652 \t final weights = [0.11702631 0.03309335]\n",
      "cost for train data = 1.5064580587634933\n",
      "cost for test data = 3.07321510850442\n",
      "BIC: 485.8377555141008\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5f66e-235d-4c4e-8d7e-2105fc63230d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9514e4e8-3b23-46b6-8ee7-9f5f466ba6a5",
   "metadata": {},
   "source": [
    "So for the bivariate model, BIC value of only model with lymph_node_status is lower than the model obtained from univariate model. So the two of the selected features are 'mean_radius' and 'lymph_node_status'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98dee3-949e-43f2-ac60-9222bb4d46ca",
   "metadata": {},
   "source": [
    "Now, continuing same process with three features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca72ab3-c471-4309-a013-a4a5f4aa4e72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "091c6dbb-fade-4bcf-ae88-bb5f7cfe4243",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "413640d4-551f-42f9-b9c2-be6a1e6bff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.   ]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.001]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.001]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.0066140734016327096 \t final weights = [0.11702409 0.03309304 0.00066327]\n",
      "cost for train data = 1.5064462224832875\n",
      "cost for test data = 3.073178356363084\n",
      "BIC: 485.83661624084846\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "046e923f-f067-4669-9e1c-c9f39c260c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.001]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.001]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.001]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.0066137549448889105 \t final weights = [0.11701864 0.03309229 0.00121891]\n",
      "cost for train data = 1.5064232262894444\n",
      "cost for test data = 3.0730900774639256\n",
      "BIC: 485.8344027708232\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b11c0447-e326-499d-8210-3cce6342e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.   ]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.   ]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.   ]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.   ]\n",
      "\n",
      "\n",
      "final bias = 0.006614155009020355 \t final weights = [0.11702549 0.03309323 0.00040645]\n",
      "cost for train data = 1.5064533798577608\n",
      "cost for test data = 3.073201238788571\n",
      "BIC: 485.8373051581279\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_fractal_dimension', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e16cb1-3eb3-4ebe-9cb3-3eaacdabf1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f7378e6-1870-4d5c-a1fe-9c974160d946",
   "metadata": {},
   "source": [
    "Here the minimum BIC value less than the previous model is obtained when we adding 'mean_symmetry' feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b463f94-53fb-4362-9abf-a058a5f1b741",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0be3e3-4fb8-44fb-9398-5497e2b0f149",
   "metadata": {},
   "source": [
    "Backward Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "226eff45-09b5-4915-b7d1-f9ef15f78d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "930cf2e0-2069-45f6-8cf6-25a8f309e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 5.031\t Bias: 0.000\t Weight: [0.    0.001]\n",
      "Iteration: 10\t Cost: 4.920\t Bias: 0.003\t Weight: [0.001 0.011]\n",
      "Iteration: 20\t Cost: 4.815\t Bias: 0.005\t Weight: [0.001 0.021]\n",
      "Iteration: 30\t Cost: 4.717\t Bias: 0.008\t Weight: [0.002 0.031]\n",
      "Iteration: 40\t Cost: 4.624\t Bias: 0.011\t Weight: [0.002 0.04 ]\n",
      "Iteration: 49\t Cost: 4.544\t Bias: 0.013\t Weight: [0.002 0.048]\n",
      "\n",
      "\n",
      "final bias = 0.012896078527013535 \t final weights = [0.00243006 0.04812692]\n",
      "cost for train data = 4.544319897648481\n",
      "cost for test data = 7.398693300108156\n",
      "BIC: 645.9346973045923\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_symmetry', 'lymph_node_status', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee7cd5-12b7-44e2-9eb4-b2806508578d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4222b-da71-42ce-9013-1e16e695aa76",
   "metadata": {},
   "source": [
    "Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "873322d0-7107-4ae5-94ee-38e5cd2a7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08a31717-e78f-48eb-acce-239810f4ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.    0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.    0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.001 0.   ]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.001 0.001]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.001 0.001]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.001 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.006613624329984617 \t final weights = [0.11701643 0.03309197 0.00121888 0.00066322]\n",
      "cost for train data = 1.5064113955501581\n",
      "cost for test data = 3.073053335118395\n",
      "BIC: 485.83326400457037\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "989b4e32-2712-4cee-92f0-f75a29d7e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.    0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.    0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.001 0.   ]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.001 0.   ]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.001 0.   ]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.001 0.   ]\n",
      "\n",
      "\n",
      "final bias = 0.006613705928679848 \t final weights = [0.11701782 0.03309217 0.0012189  0.00040642]\n",
      "cost for train data = 1.506418549507003\n",
      "cost for test data = 3.0730762114448127\n",
      "BIC: 485.8339526088138\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_fractal_dimension', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5630f3-0837-462d-bcdd-0b9e3e4885be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6d4cf32-d8b1-4602-b00f-984ee4b91d5e",
   "metadata": {},
   "source": [
    "Since the BIC after adding 'mean_smoothness' is lower than the previous selected model, we choose this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13680226-e6f4-4768-863b-7bd84720269c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "099d598a-ec7e-40e4-9614-051bdea710d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "431262a7-4f3b-46bf-9a0d-1f934f3f4f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 5.031\t Bias: 0.000\t Weight: [0.001 0.    0.   ]\n",
      "Iteration: 10\t Cost: 4.920\t Bias: 0.003\t Weight: [0.011 0.001 0.   ]\n",
      "Iteration: 20\t Cost: 4.815\t Bias: 0.005\t Weight: [0.021 0.001 0.001]\n",
      "Iteration: 30\t Cost: 4.717\t Bias: 0.008\t Weight: [0.031 0.002 0.001]\n",
      "Iteration: 40\t Cost: 4.623\t Bias: 0.011\t Weight: [0.04  0.002 0.001]\n",
      "Iteration: 49\t Cost: 4.544\t Bias: 0.013\t Weight: [0.048 0.002 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.01289574849859015 \t final weights = [0.04812612 0.00243    0.00130909]\n",
      "cost for train data = 4.543994208847065\n",
      "cost for test data = 7.398279228794519\n",
      "BIC: 650.9010386077392\n"
     ]
    }
   ],
   "source": [
    "# Remove mean_radius\n",
    "columns = ['lymph_node_status', 'mean_symmetry', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeca1d55-0c27-49b4-bd46-5b41c473b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.821\t Bias: 0.000\t Weight: [0.005 0.    0.   ]\n",
      "Iteration: 10\t Cost: 3.245\t Bias: 0.002\t Weight: [0.045 0.    0.   ]\n",
      "Iteration: 20\t Cost: 2.416\t Bias: 0.004\t Weight: [0.073 0.001 0.   ]\n",
      "Iteration: 30\t Cost: 1.980\t Bias: 0.005\t Weight: [0.094 0.001 0.001]\n",
      "Iteration: 40\t Cost: 1.751\t Bias: 0.006\t Weight: [0.109 0.001 0.001]\n",
      "Iteration: 49\t Cost: 1.639\t Bias: 0.007\t Weight: [0.12  0.001 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.006760479131436941 \t final weights = [0.11952358 0.00124696 0.00067862]\n",
      "cost for train data = 1.6389233300188395\n",
      "cost for test data = 3.5107857106716214\n",
      "BIC: 503.03484002159195\n"
     ]
    }
   ],
   "source": [
    "# Remove lymph_node_status\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f9ed3-9290-4c22-a988-c9a10eaa659e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77b8a33d-45fb-4662-836c-b22a939d42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba13c9dc-35c8-4a76-b4af-5edf8da06acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 4.811\t Bias: 0.000\t Weight: [0.005 0.001 0.    0.    0.   ]\n",
      "Iteration: 10\t Cost: 3.168\t Bias: 0.002\t Weight: [0.044 0.01  0.    0.    0.   ]\n",
      "Iteration: 20\t Cost: 2.311\t Bias: 0.004\t Weight: [0.073 0.018 0.001 0.    0.   ]\n",
      "Iteration: 30\t Cost: 1.861\t Bias: 0.005\t Weight: [0.093 0.024 0.001 0.    0.001]\n",
      "Iteration: 40\t Cost: 1.624\t Bias: 0.006\t Weight: [0.108 0.029 0.001 0.    0.001]\n",
      "Iteration: 49\t Cost: 1.506\t Bias: 0.007\t Weight: [0.117 0.033 0.001 0.    0.001]\n",
      "\n",
      "\n",
      "final bias = 0.006613575315281914 \t final weights = [0.1170156  0.03309186 0.00121887 0.00040641 0.00066321]\n",
      "cost for train data = 1.5064067194021196\n",
      "cost for test data = 3.0730394701643076\n",
      "BIC: 500.763015127352\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_fractal_dimension', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7864b-25be-4d5d-ae8e-f31bab36ccde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a3d53a-fa6e-40d1-8c3a-6f14172628f9",
   "metadata": {},
   "source": [
    "Finally, BIC value is minimum when I add 'mean_smoothness' to the model. Therefore, from the observations, we can finalize 'mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_fractal_dimension', 'mean_smoothness' (all five)  features to be included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba9385-9caa-4d4f-bc16-1f2723516934",
   "metadata": {},
   "source": [
    "### b) Backward Stepwise Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05f62a-4a10-47a5-9280-7968fb37ae47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45534ccf-0e63-49ff-a915-0b8e319c7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecdedfc1-c030-4078-bf89-9fa6283f59ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411901.299\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358163004635974231157546370233979150079038115930125107200.000\t Bias: 7008123840025124143104.000\t Weight: [1.31132009e+23 1.34992972e+21 8.66436995e+23 4.34734760e+20\n",
      " 2.22619822e+21 1.74267572e+22 7.85230370e+24 7.18762418e+20\n",
      " 1.61275621e+23 1.18438096e+25]\n",
      "Iteration: 20\t Cost: 311436906289649647846656280641565230667708186407833998678382604213086228403616667550779492492289552995581952.000\t Bias: 206655250340012240845604031040136366870562340864.000\t Weight: [3.86681498e+48 3.98066687e+46 2.55494563e+49 1.28194396e+46\n",
      " 6.56460362e+46 5.13879456e+47 2.31548389e+50 2.11948349e+46\n",
      " 4.75568847e+48 3.49249743e+50]\n",
      "Iteration: 30\t Cost: 270806714662919584272290414001610179933222128199335362634541159018986516753910849746222893127534662767986905464477790372746129277007601962985745957650004180992.000\t Bias: 6093841014792916666650939357880160075263391490533711384443816655603105792.000\t Weight: [1.14024471e+74 1.17381731e+72 7.53401255e+74 3.78019078e+71\n",
      " 1.93576745e+72 1.51532550e+73 6.82788881e+75 6.24992366e+71\n",
      " 1.40235534e+74 1.02986612e+76]\n",
      "Iteration: 40\t Cost: 235477155165155888795461156710012308920914986735068446893411816408431496226139199589718724209878296459900926659357307575531850027904797253300530971455659865377689065624196969973683809555777986338869812819656704.000\t Bias: 179694918239308949394522017827588345546102546562431957378405392709204513337738652145541027209412608.000\t Weight: [3.36234865e+099 3.46134737e+097 2.22162634e+100 1.11470101e+097\n",
      " 5.70818263e+097 4.46838523e+098 2.01340488e+101 1.84297477e+097\n",
      " 4.13525932e+099 3.03686472e+101]\n",
      "Iteration: 49\t Cost: 1649336222905884226789695571160297883280116912488381451794065863933350772771812355540140152725872833377958348203822896979027568128698378074022926110628420331524882910541741474594971817583352732449095026391727561539473150937089734502287549841389592105713664.000\t Bias: -15038897655068933597247730147065161813239966260595937201301916694131635831212394803422509011146548320358275931453532405760.000\t Weight: [-2.81399261e+122 -2.89684591e+120 -1.85930751e+123 -9.32907538e+119\n",
      " -4.77725109e+120 -3.73964878e+121 -1.68504431e+124 -1.54240917e+120\n",
      " -3.46085145e+122 -2.54159095e+124]\n",
      "\n",
      "\n",
      "final bias = -1.5038897655068934e+121 \t final weights = [-2.81399261e+122 -2.89684591e+120 -1.85930751e+123 -9.32907538e+119\n",
      " -4.77725109e+120 -3.73964878e+121 -1.68504431e+124 -1.54240917e+120\n",
      " -3.46085145e+122 -2.54159095e+124]\n",
      "cost for train data = 1.6493362229058842e+255\n",
      "cost for test data = 1.430719802312274e+255\n",
      "BIC: 85676.87413233538\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a5975-ff1f-4aa7-aef6-eb73cc08a113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f607c1d5-916a-4c98-ba6b-555c798b7df4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a5690-3f3f-4496-8aac-865cd8185155",
   "metadata": {},
   "source": [
    "Remove every features one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67acf1d2-cbec-4d29-8194-d6f384b4a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102d850-7be5-40c7-9d8b-b5a570f8f6fa",
   "metadata": {},
   "source": [
    "remove 'worst_area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7df5b250-86a7-4d33-88d1-56ac6b287f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 40268.383\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.001 0.271 0.    0.006]\n",
      "Iteration: 10\t Cost: 2322088968365462571345059694703706979432398848.000\t Bias: 57961819914774176.000\t Weight: [1.08156641e+18 1.11663670e+16 7.14676437e+18 3.59527582e+15\n",
      " 1.83405617e+16 1.44505155e+17 6.45135564e+19 5.94537784e+15\n",
      " 1.31934928e+18]\n",
      "Iteration: 20\t Cost: 133909468181229493491554658092511179627971348568617030199899975059344100461544671805440.000\t Bias: 13919006197636213086345304467912523776.000\t Weight: [2.59728379e+38 2.68150193e+36 1.71623075e+39 8.63372933e+35\n",
      " 4.40431981e+36 3.47016044e+37 1.54923464e+40 1.42772865e+36\n",
      " 3.16829782e+38]\n",
      "Iteration: 30\t Cost: 7722247473231850388652225323674264344032160803883295065248029614376161894017243753305766445614293687399277732798764942553513984.000\t Bias: 3342523299211526557115237785041304185209301894169783959552.000\t Weight: [6.23714184e+58 6.43938407e+56 4.12137273e+59 2.07331192e+56\n",
      " 1.05765752e+57 8.33327608e+57 3.72034670e+60 3.42856107e+56\n",
      " 7.60838033e+58]\n",
      "Iteration: 40\t Cost: 445324045026671719928834511111104741684609094343541591882447960991007448558540626669505249016148988003640564322334457074277059019485273522842212291763679422745487081472.000\t Bias: 802676703144887878694668054900124049926740731122051884255428349058008177704960.000\t Weight: [1.49779313e+79 1.54635977e+77 9.89710342e+79 4.97887083e+76\n",
      " 2.53986876e+77 2.00116079e+78 8.93407572e+80 8.23337895e+76\n",
      " 1.82708364e+79]\n",
      "Iteration: 49\t Cost: 2155337733892198113092077326292187472198737539819684735507192883719690762111932636110408439556429341031559621042574197105265589265621343466716704493440683309836449685069687252888542091917512808403457540096.000\t Bias: -1765876193576872921561331808835588638120144509955265371986487759621982236690121382129486188773376.000\t Weight: [-3.29512147e+97 -3.40196732e+95 -2.17734727e+98 -1.09534380e+95\n",
      " -5.58767156e+95 -4.40252244e+96 -1.96548269e+99 -1.81133049e+95\n",
      " -4.01955543e+97]\n",
      "\n",
      "\n",
      "final bias = -1.765876193576873e+96 \t final weights = [-3.29512147e+97 -3.40196732e+95 -2.17734727e+98 -1.09534380e+95\n",
      " -5.58767156e+95 -4.40252244e+96 -1.96548269e+99 -1.81133049e+95\n",
      " -4.01955543e+97]\n",
      "cost for train data = 2.155337733892198e+204\n",
      "cost for test data = 2.0868840471823516e+204\n",
      "BIC: 68683.07894050672\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f902e0-ab39-4d25-b86c-6da7c21c860f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50fbcb9b-27ad-4e36-a848-8958339fca95",
   "metadata": {},
   "source": [
    "Remove worst_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "83ce7df4-a686-4ba5-947d-842721ea9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411790.033\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.001 0.271 0.    0.4  ]\n",
      "Iteration: 10\t Cost: 357145988391351211194374948810679528630457631143977025536.000\t Bias: 6998996501151393775616.000\t Weight: [1.30961823e+23 1.34817133e+21 8.65312586e+23 4.34168060e+20\n",
      " 2.22329643e+21 1.74040684e+22 7.84214618e+24 7.17826014e+20\n",
      " 1.18285050e+25]\n",
      "Iteration: 20\t Cost: 309754418984580381080509196766267391416921035924513968632934981543507597014675471860924652269321970264309760.000\t Bias: 206120716588349313994777937724675946943940132864.000\t Weight: [3.85683073e+48 3.97036976e+46 2.54834890e+49 1.27862661e+46\n",
      " 6.54761656e+46 5.12550485e+47 2.30951507e+50 2.11400038e+46\n",
      " 3.48349927e+50]\n",
      "Iteration: 30\t Cost: 268651484824569006789521256633946083594538271743287059658048913290687572355580408197144634623003063763892974841040289921642409784516287881417140905988822401024.000\t Bias: 6070263044124283635033456365517275733922871351334091828387258692181950464.000\t Weight: [1.13583814e+74 1.16927542e+72 7.50489732e+74 3.76556029e+71\n",
      " 1.92827560e+72 1.50946315e+73 6.80153078e+75 6.22573926e+71\n",
      " 1.02589188e+76]\n",
      "Iteration: 40\t Cost: 233002714004988500909862073343850012138228261266284063565995959391546591254917796449027045160443769409649395994497993488549933989259396757225917138097709253833960275489672779707986634881536623651182855529168896.000\t Bias: 178769480500359681298002502422385498513388879445182671537056691995383756072276287572743360035684352.000\t Weight: [3.34504769e+099 3.44352063e+097 2.21019515e+100 1.10895896e+097\n",
      " 5.67877907e+097 4.44537480e+098 2.00305344e+101 1.83348261e+097\n",
      " 3.02125553e+101]\n",
      "Iteration: 49\t Cost: 1628229206655629714258146293428640946260122544788539588136151080580324231820642730757804672746633246782751275167470405622687666173980435367773935594391845902789871400401664907554168387706330230297120928474791984081527664376886646296200721319538499627515904.000\t Bias: -14944130748249611793038140995920155152344491858155732582011765039952210012113906674296977119558702446289368538186816421888.000\t Weight: [-2.79627316e+122 -2.87859104e+120 -1.84759978e+123 -9.27027789e+119\n",
      " -4.74714233e+120 -3.71608521e+121 -1.67444087e+124 -1.53268912e+120\n",
      " -2.52560099e+124]\n",
      "\n",
      "\n",
      "final bias = -1.4944130748249612e+121 \t final weights = [-2.79627316e+122 -2.87859104e+120 -1.84759978e+123 -9.27027789e+119\n",
      " -4.74714233e+120 -3.71608521e+121 -1.67444087e+124 -1.53268912e+120\n",
      " -2.52560099e+124]\n",
      "cost for train data = 1.6282292066556297e+255\n",
      "cost for test data = 1.412392320153798e+255\n",
      "BIC: 85670.0298174683\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46c131-69f8-4672-b25d-5b1d9c5fbd9c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13d48a-6eef-414d-86ee-e6b33e939a2f",
   "metadata": {},
   "source": [
    "Remove mean_smoothness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55cd8472-05f6-4ce3-ada0-7759c8672dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411901.296\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.001 0.271 0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358162984317082886684449182088679903552362858222551302144.000\t Bias: 7008123655967792431104.000\t Weight: [1.31132006e+23 1.34992968e+21 8.66436972e+23 4.34734748e+20\n",
      " 2.22619817e+21 1.74267567e+22 7.85230350e+24 1.61275616e+23\n",
      " 1.18438093e+25]\n",
      "Iteration: 20\t Cost: 311436872703654603036370220419455243453343086506299971444999709173206776869674475975863883623523230072963072.000\t Bias: 206655239631338110729780130580485796376394858496.000\t Weight: [3.86681478e+48 3.98066666e+46 2.55494550e+49 1.28194390e+46\n",
      " 6.56460328e+46 5.13879429e+47 2.31548377e+50 4.75568823e+48\n",
      " 3.49249725e+50]\n",
      "Iteration: 30\t Cost: 270806671617310812150092738090379802366257536723896011234602131812131442895540603503561265812519258595348144650130445175295424423394573389986758378472232452096.000\t Bias: 6093840543284224355208024709599308805263792220964419761707670570352508928.000\t Weight: [1.14024463e+74 1.17381722e+72 7.53401197e+74 3.78019048e+71\n",
      " 1.93576730e+72 1.51532538e+73 6.82788829e+75 1.40235524e+74\n",
      " 1.02986604e+76]\n",
      "Iteration: 40\t Cost: 235477105699775677213773791756629175042259284615999907363499829382882108400655529238263226698122154992466934420096229943638319820748824580333931767093435677498476646648947263298197954856480910189794396077031424.000\t Bias: 179694899743269067577608077079383740658291094645306311089990402254369854842279363739869243965964288.000\t Weight: [3.36234830e+099 3.46134701e+097 2.22162611e+100 1.11470089e+097\n",
      " 5.70818204e+097 4.46838477e+098 2.01340467e+101 4.13525890e+099\n",
      " 3.03686441e+101]\n",
      "Iteration: 49\t Cost: 1649335800569374852783078371656111873927394809805591599868374997608823562887933331870273644428877004695388768824064586555305279228169821904553545332161803960618947045929281438811793188927715764813968881062158652291234159397861625292646746230070751407374336.000\t Bias: -15038895761216430663544922208502452291795024018674679435849985735567336424097166184546192268470729571861636327038936678400.000\t Weight: [-2.81399225e+122 -2.89684554e+120 -1.85930728e+123 -9.32907421e+119\n",
      " -4.77725049e+120 -3.73964831e+121 -1.68504409e+124 -3.46085101e+122\n",
      " -2.54159063e+124]\n",
      "\n",
      "\n",
      "final bias = -1.503889576121643e+121 \t final weights = [-2.81399225e+122 -2.89684554e+120 -1.85930728e+123 -9.32907421e+119\n",
      " -4.77725049e+120 -3.73964831e+121 -1.68504409e+124 -3.46085101e+122\n",
      " -2.54159063e+124]\n",
      "cost for train data = 1.6493358005693749e+255\n",
      "cost for test data = 1.4307194353600631e+255\n",
      "BIC: 85671.89736146359\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882a2bc-d78d-4784-afc5-99d8e2748142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63db7fea-5506-4bfd-bbb0-6a5f18aeb300",
   "metadata": {},
   "source": [
    "Remove 'mean_area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "252a11e6-0fa7-49e7-b08a-2faa707ac4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 196850.978\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.001 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 123832179954218214948553153565079028441703519514263552.000\t Bias: 185176746800245964800.000\t Weight: [3.46852724e+21 3.56675974e+19 2.29171014e+22 1.14880877e+19\n",
      " 5.89289548e+19 4.59934443e+20 1.89913330e+19 4.28132231e+21\n",
      " 3.16138261e+23]\n",
      "Iteration: 20\t Cost: 77899248368159981563328663967172293709922578006678570781810422155435552988600877391235678079536857088.000\t Bias: 146871092227036671463786294941873198111653888.000\t Weight: [2.75102783e+45 2.82893996e+43 1.81764707e+46 9.11166232e+42\n",
      " 4.67389136e+43 3.64792422e+44 1.50627866e+43 3.39568814e+45\n",
      " 2.50741913e+47]\n",
      "Iteration: 30\t Cost: 49004167564260896570779309761548024453257807427309546067128756407517024932059646048042924073250519335083829358515782200411338191963856106464584138752.000\t Bias: 116489343854991954632176315127907034493264094256597690287119751184384.000\t Weight: [2.18195032e+69 2.24374555e+67 1.44164867e+70 7.22682421e+66\n",
      " 3.70705037e+67 2.89331476e+68 1.19468991e+67 2.69325623e+69\n",
      " 1.98873451e+71]\n",
      "Iteration: 40\t Cost: 30827106666252581111506215647655566077557777030229245689943170333610110938337414485491722269043234799466083417976732370026060116335536922939894934197209784705836208903976232890020783982958308491264.000\t Bias: 92392362758425722726149426754272838298724742139538281472159348171031365225374354988811157504.000\t Weight: [1.73059216e+93 1.77960443e+91 1.14342928e+94 5.73188364e+90\n",
      " 2.94021008e+91 2.29480378e+92 9.47556406e+90 2.13612935e+93\n",
      " 1.57734496e+95]\n",
      "Iteration: 49\t Cost: 321930807686994908733665208269348478953904198629755237445600165666712446412437080548544384791744205148192296393089821400838002267562220257741584112787606686984472009828989463573455689715337414403734823560402634590591039299860101469306880000.000\t Bias: -298573294707503889293850871031565723493223548881952097157796461741392365601262364521660808516915018218003364839424.000\t Weight: [-5.59254671e+114 -5.75093377e+112 -3.69508299e+115 -1.85230395e+112\n",
      " -9.50152355e+112 -7.41584158e+113 -3.06210416e+112 -6.90307249e+114\n",
      " -5.09731615e+116]\n",
      "\n",
      "\n",
      "final bias = -2.985732947075039e+113 \t final weights = [-5.59254671e+114 -5.75093377e+112 -3.69508299e+115 -1.85230395e+112\n",
      " -9.50152355e+112 -7.41584158e+113 -3.06210416e+112 -6.90307249e+114\n",
      " -5.09731615e+116]\n",
      "cost for train data = 3.219308076869949e+239\n",
      "cost for test data = 2.65445156580725e+239\n",
      "BIC: 80426.87504552057\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de72b3-5dcb-48f9-9cc5-f0f6172a2383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22271ed8-34a4-45d5-bd0a-3b3d3137f42a",
   "metadata": {},
   "source": [
    "Remove 'lymph_node_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7aa3516f-3763-4a66-80a8-001ecf3d267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411899.141\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.    0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358150365749550062805245254784152339798878676962806595584.000\t Bias: 7008008868668336242688.000\t Weight: [1.31129874e+23 1.34990758e+21 8.66422889e+23 4.34727612e+20\n",
      " 2.22616172e+21 7.85217668e+24 7.18750607e+20 1.61272999e+23\n",
      " 1.18436186e+25]\n",
      "Iteration: 20\t Cost: 311416559545977514027517481175164361293059981631245494765829141553717863448245881587390117236557562412793856.000\t Bias: 206648755638639794717951063309425792740340269056.000\t Weight: [3.86669391e+48 3.98054179e+46 2.55486566e+49 1.28190363e+46\n",
      " 6.56439735e+46 2.31541165e+50 2.11941682e+46 4.75553973e+48\n",
      " 3.49238862e+50]\n",
      "Iteration: 30\t Cost: 270780886560005468786749009442271581238067079739377054573480308663434709719425561325101454206882033829182762086334132061555170382905612267434492451786772709376.000\t Bias: 6093557957370684699521269178592845328403884379421138107136632628289994752.000\t Weight: [1.14019189e+74 1.17376280e+72 7.53366354e+74 3.78001505e+71\n",
      " 1.93567755e+72 6.82757322e+75 6.24963319e+71 1.40229042e+74\n",
      " 1.02981856e+76]\n",
      "Iteration: 40\t Cost: 235447622416485862096373963670049749270160626309685508016183708079484841829253051209133053438667793245415459201387243960087850986721726595154891577910613603667395943586367724956693186325714433420474264967970816.000\t Bias: 179683872109862361217267243551198447592691700860799041803821858052782885924850706524279685127340032.000\t Weight: [3.36214236e+099 3.46113462e+097 2.22149005e+100 1.11463245e+097\n",
      " 5.70783177e+097 2.01328157e+101 1.84286143e+097 4.13500575e+099\n",
      " 3.03667887e+101]\n",
      "Iteration: 49\t Cost: 1649084775668850601399835310433529676646066748053652296687677322943696256787747626303755738219376331448435782781111780177025252310584127653266903318334132442048438839658433911786883152314239338085541515679240851315334872241489119636290563593173013798846464.000\t Bias: -15037769872824847293755772148535485718044863598856973163306141791411022128354763901489323696640104345917976649410939977728.000\t Weight: [-2.81378192e+122 -2.89662869e+120 -1.85916831e+123 -9.32837545e+119\n",
      " -4.77689287e+120 -1.68491833e+124 -1.54229346e+120 -3.46059243e+122\n",
      " -2.54140105e+124]\n",
      "\n",
      "\n",
      "final bias = -1.5037769872824847e+121 \t final weights = [-2.81378192e+122 -2.89662869e+120 -1.85916831e+123 -9.32837545e+119\n",
      " -4.77689287e+120 -1.68491833e+124 -1.54229346e+120 -3.46059243e+122\n",
      " -2.54140105e+124]\n",
      "BIC: 85671.87529113641\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "# print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316f637-956e-4f55-8786-aabc13fa60e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d12546-3b16-4d48-8d50-0424e6f11f35",
   "metadata": {},
   "source": [
    "Remove 'worst_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d53a2fc5-5bda-4751-901b-ae88f2ea8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411901.276\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358162809799939924579413614825492230876958266545657610240.000\t Bias: 7008122074140110749696.000\t Weight: [1.31131977e+23 1.34992938e+21 8.66436778e+23 4.34734650e+20\n",
      " 1.74267528e+22 7.85230176e+24 7.18762237e+20 1.61275580e+23\n",
      " 1.18438067e+25]\n",
      "Iteration: 20\t Cost: 311436584170670806180494044974936626564104495090847562249687231001182529523134117344963859498861168682860544.000\t Bias: 206655147604848574325311713102374468052274118656.000\t Weight: [3.86681306e+48 3.98066489e+46 2.55494437e+49 1.28194333e+46\n",
      " 5.13879200e+47 2.31548275e+50 2.11948243e+46 4.75568612e+48\n",
      " 3.49249571e+50]\n",
      "Iteration: 30\t Cost: 270806301787931102496284041432710725368502689017742395408838124106748127170430155340458809499038472655410029555399838980597399423689075091208087202479948693504.000\t Bias: 6093836491400135061556011360091789412203511805739509086870762601955983360.000\t Weight: [1.14024387e+74 1.17381644e+72 7.53400697e+74 3.78018797e+71\n",
      " 1.51532438e+73 6.82788377e+75 6.24991902e+71 1.40235431e+74\n",
      " 1.02986536e+76]\n",
      "Iteration: 40\t Cost: 235476680696789235244416624864262823674849374578604127759580666850014302379976471853664181015009795852468999694984376738949184967702204035878585364128540785941780613699786328422039197069573615435961784514641920.000\t Bias: 179694740800391304979712666747999137460706883850428095228529665184172269338812265903172971281776640.000\t Weight: [3.36234533e+099 3.46134395e+097 2.22162415e+100 1.11469991e+097\n",
      " 4.46838082e+098 2.01340290e+101 1.84297295e+097 4.13525525e+099\n",
      " 3.03686174e+101]\n",
      "Iteration: 49\t Cost: 1649332171800427263866516035586178507322997728491829529322559247943923157716018394176488112351771411924573294740197382844526101570956787443665346291791142421979308858624478964910340453264678461802457341738329408701324299318776939229660652888654064115515392.000\t Bias: -15038879486789681386013759333571990875551153492433973699771354401549517721380235274307251575157546289261696106474902650880.000\t Weight: [-2.81398921e+122 -2.89684241e+120 -1.85930527e+123 -9.32906410e+119\n",
      " -3.73964426e+121 -1.68504228e+124 -1.54240730e+120 -3.46084727e+122\n",
      " -2.54158789e+124]\n",
      "\n",
      "\n",
      "final bias = -1.5038879486789681e+121 \t final weights = [-2.81398921e+122 -2.89684241e+120 -1.85930527e+123 -9.32906410e+119\n",
      " -3.73964426e+121 -1.68504228e+124 -1.54240730e+120 -3.46084727e+122\n",
      " -2.54158789e+124]\n",
      "cost for train data = 1.6493321718004273e+255\n",
      "cost for test data = 1.4307162804286927e+255\n",
      "BIC: 85671.897042443\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d98a7-32f0-49a8-add1-e32ab2971afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f2ddf1c-06f6-480e-8b1f-b9207d456db9",
   "metadata": {},
   "source": [
    "Remove 'mean_fractal_dimension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efbb1eda-715c-4b87-8419-3dc435b16266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411901.298\t Bias: 0.000\t Weight: [0.005 0.    0.031 0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358162997196018913395093762649465047151831561289601122304.000\t Bias: 7008123772545292828672.000\t Weight: [1.31132008e+23 1.34992970e+21 8.66436987e+23 2.22619820e+21\n",
      " 1.74267570e+22 7.85230363e+24 7.18762411e+20 1.61275619e+23\n",
      " 1.18438095e+25]\n",
      "Iteration: 20\t Cost: 311436893997080564251060942338216960437885975625612053888494614815593113954111438175480108823593755550416896.000\t Bias: 206655246418154448776135042959568359027770392576.000\t Weight: [3.86681490e+48 3.98066679e+46 2.55494559e+49 6.56460350e+46\n",
      " 5.13879446e+47 2.31548385e+50 2.11948345e+46 4.75568838e+48\n",
      " 3.49249736e+50]\n",
      "Iteration: 30\t Cost: 270806698910511866981980051048162466941670318782182487944866329333171331849010299930272159158041642256882153368899776386786534819044449846674813014586960117760.000\t Bias: 6093840842174159187355538859188377143882284628865787777150052913431707648.000\t Weight: [1.14024468e+74 1.17381728e+72 7.53401234e+74 1.93576740e+72\n",
      " 1.51532546e+73 6.82788862e+75 6.24992349e+71 1.40235530e+74\n",
      " 1.02986609e+76]\n",
      "Iteration: 40\t Cost: 235477137064872514263736500183419594919816949430308866898844431143309730558811910281461724722643904438396404559850934353159987996849038458546651369567750585221728984955064349984859790255368021861056036441423872.000\t Bias: 179694911469170389642824721327733820446265038928451675751831151887478558109595689187069453714587648.000\t Weight: [3.36234852e+099 3.46134724e+097 2.22162625e+100 5.70818242e+097\n",
      " 4.46838506e+098 2.01340480e+101 1.84297470e+097 4.13525917e+099\n",
      " 3.03686461e+101]\n",
      "Iteration: 49\t Cost: 1649336068372040467401306471384106761311110851466862123881893002938060924505283454294893383066694347741584110148025876215573127950323417878109362789159634132992668884354051958007350847379604873121049136572411559467424475885468688372929144410907735352147968.000\t Bias: -15038896961928903393551537053012048526461053733572115695143698767627044472639023397247037585296687438488561792375792336896.000\t Weight: [-2.81399248e+122 -2.89684577e+120 -1.85930743e+123 -4.77725087e+120\n",
      " -3.73964861e+121 -1.68504423e+124 -1.54240909e+120 -3.46085129e+122\n",
      " -2.54159083e+124]\n",
      "\n",
      "\n",
      "final bias = -1.5038896961928903e+121 \t final weights = [-2.81399248e+122 -2.89684577e+120 -1.85930743e+123 -4.77725087e+120\n",
      " -3.73964861e+121 -1.68504423e+124 -1.54240909e+120 -3.46085129e+122\n",
      " -2.54159083e+124]\n",
      "cost for train data = 1.6493360683720405e+255\n",
      "cost for test data = 1.4307196680529068e+255\n",
      "BIC: 85671.89738500724\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278f61d-59b1-43d4-b741-4248c04a077a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7107c575-04d2-4dbf-9d64-8e755fedc331",
   "metadata": {},
   "source": [
    "Remove 'mean_perimeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a23738c4-5bdc-4e5d-a1b8-542a7eafcaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 408673.793\t Bias: 0.000\t Weight: [0.005 0.    0.    0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 329879158795556001934997933845100270689958504070855524352.000\t Bias: 6748502225097834102784.000\t Weight: [1.26291531e+23 1.29990930e+21 4.18614370e+20 2.14368364e+21\n",
      " 1.67810692e+22 7.56344647e+24 6.92124770e+20 1.55328939e+23\n",
      " 1.14090835e+25]\n",
      "Iteration: 20\t Cost: 266277690589884122528999624278489365404779286955332266236677793086278616636620815263101772666650909640491008.000\t Bias: 191733211656985101491752391644517294488546181120.000\t Weight: [3.58809704e+48 3.69320149e+46 1.18933468e+46 6.09046770e+46\n",
      " 4.76770725e+47 2.14886775e+50 1.96641122e+46 4.41308535e+48\n",
      " 3.24146031e+50]\n",
      "Iteration: 30\t Cost: 214938733216016905336625556534894462373428217563958708146492934558891954369744252566484625713534552211935679027915951954325958328609790393368865952181832908800.000\t Bias: 5447375317679370374596325893963928364654153541809444736845112521412050944.000\t Weight: [1.01942231e+74 1.04928376e+72 3.37904547e+71 1.73037645e+72\n",
      " 1.35456401e+73 6.10519642e+75 5.58681506e+71 1.25381159e+74\n",
      " 9.20938566e+75]\n",
      "Iteration: 40\t Cost: 173498046096773177429144287228065549463716341381888929725089906147495333593401397855991345581435584974086248033532365762917095806379377404838638718739024127198873996530557274556564549885279543134479902291525632.000\t Bias: 154766603006419529875970614324973368103616627698238703720430170893869025392003877959554498513862656.000\t Weight: [2.89630360e+099 2.98114366e+097 9.60028193e+096 4.91621138e+097\n",
      " 3.84848222e+098 1.73456106e+101 1.58728257e+097 3.56223224e+099\n",
      " 2.61649923e+101]\n",
      "Iteration: 49\t Cost: 1136518478215534277252561452012729401717214050868781751284104036652407657153834610879372937557827122381022880708914273295620742923102916463694249799117832771936114731173712633407605519529528119853626959384986796734914529445816210275860940345284331814518784.000\t Bias: -12526167268757730396782200084627781395751711567845829660468450973216718542249075129353714569469617922402146745035335401472.000\t Weight: [-2.34414807e+122 -2.41281410e+120 -7.77007022e+119 -3.97897769e+120\n",
      " -3.11480197e+121 -1.40388182e+124 -1.28468071e+120 -2.88312311e+122\n",
      " -2.11768601e+124]\n",
      "\n",
      "\n",
      "final bias = -1.252616726875773e+121 \t final weights = [-2.34414807e+122 -2.41281410e+120 -7.77007022e+119 -3.97897769e+120\n",
      " -3.11480197e+121 -1.40388182e+124 -1.28468071e+120 -2.88312311e+122\n",
      " -2.11768601e+124]\n",
      "cost for train data = 1.1365184782155343e+255\n",
      "cost for test data = 9.852346652556538e+254\n",
      "BIC: 85617.89892085164\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd8cd8-a284-4788-8a8e-cf4385bed164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16ac61f4-a53f-4f60-8547-311503eeb6ea",
   "metadata": {},
   "source": [
    "Remove 'mean_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2a71974-4460-4cb0-aea0-6cdaedd4206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411901.290\t Bias: 0.000\t Weight: [0.005 0.031 0.    0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 358162933047260465299382135939441078965866608793206390784.000\t Bias: 7008123191993210765312.000\t Weight: [1.31131997e+23 8.66436915e+23 4.34734719e+20 2.22619802e+21\n",
      " 1.74267556e+22 7.85230299e+24 7.18762351e+20 1.61275606e+23\n",
      " 1.18438086e+25]\n",
      "Iteration: 20\t Cost: 311436787891989805216246545623829057317675811937519706457354174966281622236220279563954805634324553560752128.000\t Bias: 206655212602107417612568388893201163570437423104.000\t Weight: [3.86681427e+48 2.55494517e+49 1.28194373e+46 6.56460242e+46\n",
      " 5.13879362e+47 2.31548347e+50 2.11948310e+46 4.75568761e+48\n",
      " 3.49249680e+50]\n",
      "Iteration: 30\t Cost: 270806562888185056758882783456980035011503454177046088097958387403655337794090282030043462131190414467328045809081473542665100347832128365278767394290355142656.000\t Bias: 6093839352654960911349861174148228448510426230173166843695736944884449280.000\t Weight: [1.14024440e+74 7.53401050e+74 3.78018974e+71 1.93576693e+72\n",
      " 1.51532509e+73 6.82788696e+75 6.24992196e+71 1.40235496e+74\n",
      " 1.02986584e+76]\n",
      "Iteration: 40\t Cost: 235476980737248966616220390932133221373749307185579997369555589719464810861526834180540956552283312403686276104306515808225203649365725201058906497248783723965214072300670248529434726627297824646437143358472192.000\t Bias: 179694853027808651067479432281094259155315829517511154070637140042691391533301355320559603520897024.000\t Weight: [3.36234743e+099 2.22162553e+100 1.11470060e+097 5.70818056e+097\n",
      " 4.46838361e+098 2.01340415e+101 1.84297410e+097 4.13525783e+099\n",
      " 3.03686363e+101]\n",
      "Iteration: 49\t Cost: 1649334733552328983494760825976969028303043551084172952604285653080916734317735115481671263949533750614060019887596635517259717247257996976906324597218949717679346659392963736360036979098470683453037158569635057291298312443767840979701300042188714405789696.000\t Bias: -15038890977333188455609276763250095397950862127302623735024580588951810846505545853661177800279893684843630811448183095296.000\t Weight: [-2.81399136e+122 -1.85930669e+123 -9.32907124e+119 -4.77724897e+120\n",
      " -3.73964712e+121 -1.68504356e+124 -1.54240848e+120 -3.46084991e+122\n",
      " -2.54158982e+124]\n",
      "\n",
      "\n",
      "final bias = -1.5038890977333188e+121 \t final weights = [-2.81399136e+122 -1.85930669e+123 -9.32907124e+119 -4.77724897e+120\n",
      " -3.73964712e+121 -1.68504356e+124 -1.54240848e+120 -3.46084991e+122\n",
      " -2.54158982e+124]\n",
      "cost for train data = 1.649334733552329e+255\n",
      "cost for test data = 1.4307185078817026e+255\n",
      "BIC: 85671.89726765764\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7daa3e5-9a03-4bb0-a5c3-faf9edb7d612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07d78ada-d13d-430e-b16c-16536d9f0661",
   "metadata": {},
   "source": [
    "Remove 'mean_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4a6a3f1-7f6a-4ef6-9000-5430bef9603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 411827.022\t Bias: 0.000\t Weight: [0.    0.031 0.    0.    0.001 0.271 0.    0.006 0.4  ]\n",
      "Iteration: 10\t Cost: 357489705582407049827304728823051934279679614662983286784.000\t Bias: 7002074291010557444096.000\t Weight: [1.34876433e+21 8.65691902e+23 4.34359174e+20 2.22427571e+21\n",
      " 1.74117087e+22 7.84557472e+24 7.18141797e+20 1.61137076e+23\n",
      " 1.18336829e+25]\n",
      "Iteration: 20\t Cost: 310323045945574171133538059788209009598386364319077278548578062726641551755472450790074462428910564967186432.000\t Bias: 206301297234652582814187992999758544049648173056.000\t Weight: [3.97384860e+46 2.55057794e+49 1.27974736e+46 6.55335755e+46\n",
      " 5.12999141e+47 2.31153252e+50 2.11585279e+46 4.74756286e+48\n",
      " 3.48654417e+50]\n",
      "Iteration: 30\t Cost: 269379485174406033015927598205712162861932385885162939742784419331036844745694062201684590478726021979094936523810435953810325705699605764482406791175529824256.000\t Bias: 6078231031530232570219999172301463254711306546356497959087724919751966720.000\t Weight: [1.17081037e+72 7.51473801e+74 3.77050471e+71 1.93080808e+72\n",
      " 1.51144338e+73 6.81044127e+75 6.23391237e+71 1.39876890e+74\n",
      " 1.02723644e+76]\n",
      "Iteration: 40\t Cost: 233837956867550130315989194230931240652202501599403177097240562825750131644928411696377782691514972334986297217676408305495450101250448500039264903662834796399458964104050185216513757009255527361371206957662208.000\t Bias: 179082211153693898276424946008809200326509350625013164812334422562814719354625248627720042783440896.000\t Weight: [3.44954493e+097 2.21405849e+100 1.11089940e+097 5.68871731e+097\n",
      " 4.45314798e+098 2.00655236e+101 1.83669032e+097 4.12117648e+099\n",
      " 3.02653472e+101]\n",
      "Iteration: 49\t Cost: 1635348993675148095973618059860960595718306281484147920548290588050458089513595088319354480992897592287155536403441812107166833933696157792788408794646682438952216387420153274983982803060548493941446566857246767566157929118041498806819868046475809989328896.000\t Bias: -14976149548230876421253727143589891311259859680098482911843593422742065045783986956644708605599614864858837635572009271296.000\t Weight: [-2.88475893e+120 -1.85155582e+123 -9.29014414e+119 -4.75731680e+120\n",
      " -3.72404437e+121 -1.67802419e+124 -1.53597327e+120 -3.44642580e+122\n",
      " -2.53100720e+124]\n",
      "\n",
      "\n",
      "final bias = -1.4976149548230876e+121 \t final weights = [-2.88475893e+120 -1.85155582e+123 -9.29014414e+119 -4.75731680e+120\n",
      " -3.72404437e+121 -1.67802419e+124 -1.53597327e+120 -3.44642580e+122\n",
      " -2.53100720e+124]\n",
      "cost for train data = 1.635348993675148e+255\n",
      "cost for test data = 1.4185651882747833e+255\n",
      "BIC: 85670.66247934569\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2b2f5-5183-4e37-b01b-081e3a1a5d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7acc2850-5342-42ff-b111-50477214dbc0",
   "metadata": {},
   "source": [
    "The least BIC value is given when we remove the 'worst_area'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02051529-ec8a-4f76-a2c3-4ef88531f953",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4146af1a-3c4e-4d5e-bf75-995f7bd49176",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "n = target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea1288-8837-437e-9736-4ef89584a799",
   "metadata": {},
   "source": [
    "Remove 'worst_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cac69547-4d87-4a4a-b5c0-d0199ff6c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7301047166535294e+96 \t final weights = [-3.22841507e+97 -3.33305170e+95 -2.13326972e+98 -1.07315135e+95\n",
      " -5.47445345e+95 -4.31335123e+96 -1.92571648e+99 -1.77463605e+95]\n",
      "cost for train data = 2.0672964872214308e+204\n",
      "cost for test data = 2.0016565971607182e+204\n",
      "BIC: 68672.05487685636\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09a189-eec2-4334-82bf-4db5583f98ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da0fb50-d538-4cb3-97f1-cd083ae9ead5",
   "metadata": {},
   "source": [
    "Remove 'mean_smoothness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "468b123d-5b9c-4aa2-8a24-7910f7a6d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.765875458054072e+96 \t final weights = [-3.29512010e+97 -3.40196590e+95 -2.17734637e+98 -1.09534334e+95\n",
      " -5.58766923e+95 -4.40252061e+96 -1.96548187e+99 -4.01955376e+97]\n",
      "cost for train data = 2.1553359075360679e+204\n",
      "cost for test data = 2.0868822783916424e+204\n",
      "BIC: 68678.10208389643\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9d944-6acf-4191-b6cd-5338ecadffeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82a63044-d2e4-4ef5-9c76-d3922b9d3ece",
   "metadata": {},
   "source": [
    "Remove 'mean_area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f8379d0-5b4e-40d8-b115-11699d4b1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0003528969713991515 \t final weights = [3.69147980e-03 8.72839265e-06 2.08468986e-02 1.41939336e-05\n",
      " 3.31564123e-05 1.86006687e-02 1.81469889e-05 4.75777209e-03]\n",
      "cost for train data = 1.4428057992878125\n",
      "cost for test data = 2.7182554659265104\n",
      "BIC: 509.4382832896177\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f21b97-c8db-43d3-a876-b6be604d2749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b35331-abf8-4a85-aed8-8c32154630b1",
   "metadata": {},
   "source": [
    "Remove 'lymph_node_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d3a3785d-7b71-498e-8437-c7af23222f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7654362813038402e+96 \t final weights = [-3.29430181e+97 -3.40111991e+95 -2.17680570e+98 -1.09507080e+95\n",
      " -5.58627955e+95 -1.96499443e+99 -1.81087910e+95 -4.01855580e+97]\n",
      "cost for train data = 2.1542456655714977e+204\n",
      "cost for test data = 2.0857952863243386e+204\n",
      "BIC: 68678.02871942447\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c2f0a-67a9-4695-b527-988287921bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d28bcf-bf97-47e0-a542-36ce1bd0b81c",
   "metadata": {},
   "source": [
    "Remove 'worst_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9bb5b5a3-2b83-46f5-b807-ca700cdd02de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7658691927232507e+96 \t final weights = [-3.29510843e+97 -3.40195382e+95 -2.17733866e+98 -1.09533945e+95\n",
      " -4.40250499e+96 -1.96547492e+99 -1.81132331e+95 -4.01953952e+97]\n",
      "cost for train data = 2.1553203539967356e+204\n",
      "cost for test data = 2.0868672052720978e+204\n",
      "BIC: 68678.10103752991\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610a897-8d88-445c-a277-abbcc1b85f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a6ca015-81a1-4399-8c3d-f796f42f56f1",
   "metadata": {},
   "source": [
    "Remove 'mean_fractal_dimension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2bacf978-59c8-4379-a641-b8b0b3501e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7658759244873175e+96 \t final weights = [-3.29512097e+97 -3.40196680e+95 -2.17734694e+98 -5.58767071e+95\n",
      " -4.40252177e+96 -1.96548239e+99 -1.81133022e+95 -4.01955482e+97]\n",
      "cost for train data = 2.1553370658905468e+204\n",
      "cost for test data = 2.0868834002850455e+204\n",
      "BIC: 68678.10216182459\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f25fd-c073-46a8-b287-219aed45409c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c86121b8-8120-4681-acfd-6ba2acaf343d",
   "metadata": {},
   "source": [
    "Remove 'mean_perimeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0521a2c5-279b-4955-9941-f191cf7e0721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.765876193576873e+96 \t final weights = [-3.29512147e+97 -3.40196732e+95 -2.17734727e+98 -1.09534380e+95\n",
      " -5.58767156e+95 -4.40252244e+96 -1.96548269e+99 -1.81133049e+95\n",
      " -4.01955543e+97]\n",
      "cost for train data = 2.155337733892198e+204\n",
      "cost for test data = 2.0868840471823516e+204\n",
      "BIC: 68678.1022067643\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc2b1e-c7c0-402c-ab18-a811f69e610c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abffecf2-0ee8-414e-9d36-753ca9ca2922",
   "metadata": {},
   "source": [
    "Remove mean_symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e0a3bcf-10bf-46bd-b283-340a034278a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7658736000143315e+96 \t final weights = [-3.29511664e+97 -2.17734408e+98 -1.09534219e+95 -5.58766334e+95\n",
      " -4.40251598e+96 -1.96547981e+99 -1.81132783e+95 -4.01954954e+97]\n",
      "cost for train data = 2.155331293081649e+204\n",
      "cost for test data = 2.0868778076417684e+204\n",
      "BIC: 68678.10177345916\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945aa38-f4c1-4c1e-a351-3d6e8ec4376c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c330f31a-893e-4fa3-a29d-a9d2e38585a0",
   "metadata": {},
   "source": [
    "Remove 'mean_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db9dbd24-4f76-4b51-a4db-c9ea65ae1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.7417548454283567e+96 \t final weights = [-3.35549679e+95 -2.14762618e+98 -1.08037920e+95 -5.51133269e+95\n",
      " -4.34238438e+96 -1.93867015e+99 -1.78658695e+95 -3.96468999e+97]\n",
      "cost for train data = 2.095769947273318e+204\n",
      "cost for test data = 2.0291805986731424e+204\n",
      "BIC: 68674.03837443094\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_area', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6af43-741a-4b1e-898a-e8b4b047f4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d40935b2-03a6-49b4-b038-3586cfde224e",
   "metadata": {},
   "source": [
    "Removing 'mean_area' makes more sense on this step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55eae1-d062-4245-a62a-5a3c614d5222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 4\n",
    "Forward Step (Add two features removed and compare with the 8 predictor model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec173310-5199-4fb8-a5aa-1191be1eb696",
   "metadata": {},
   "source": [
    "Add 'worst_area' and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0a32a40b-6419-4fb3-9e51-724f00e1702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -2.985732947075039e+113 \t final weights = [-5.59254671e+114 -5.75093377e+112 -3.69508299e+115 -1.85230395e+112\n",
      " -9.50152355e+112 -7.41584158e+113 -3.06210416e+112 -6.90307249e+114\n",
      " -5.09731615e+116]\n",
      "cost for train data = 3.219308076869949e+239\n",
      "cost for test data = 2.65445156580725e+239\n",
      "BIC: 80421.89831177816\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5cfee2ba-54b0-4c8b-94af-4dc41cf53ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -1.765876193576876e+96 \t final weights = [-3.29512147e+97 -3.40196732e+95 -2.17734727e+98 -1.09534380e+95\n",
      " -5.58767156e+95 -4.40252244e+96 -1.81133049e+95 -4.01955543e+97\n",
      " -1.96548269e+99]\n",
      "cost for train data = 2.1553377338922056e+204\n",
      "cost for test data = 2.086884047182359e+204\n",
      "BIC: 68678.1022067643\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'mean_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e375ff5-48f3-40f9-90ec-1e743ab87578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "711e65e0-b4b3-4a59-be5b-4046248a80e2",
   "metadata": {},
   "source": [
    "Since adding the removed features does not improve the BIC score. We go on with the 8 predictor model from step 3 and move on to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a948e15-7442-4af7-9a67-313672978d27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44693f28-2137-4f14-9823-40b6f26a5445",
   "metadata": {},
   "source": [
    "Remove 'worst_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd06cb22-c6de-44a3-9c15-257553d7e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.00035970859687476617 \t final weights = [3.82290555e-03 9.97573005e-06 2.17010893e-02 1.46033321e-05\n",
      " 3.57427021e-05 1.86108672e-02 1.88113894e-05]\n",
      "cost for train data = 1.4436669627198118\n",
      "cost for test data = 2.714916479186959\n",
      "BIC: 509.52480321316466\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e0425-020e-4443-8849-1460a21de9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90367a3e-af48-4177-b54f-0b42f68f72c5",
   "metadata": {},
   "source": [
    "Remove 'mean_smoothness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "190e3dd0-45df-45d5-be5b-d2e2e94e058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0003528974459961783 \t final weights = [3.69148201e-03 8.72850043e-06 2.08469135e-02 1.41939738e-05\n",
      " 3.31566111e-05 1.86006701e-02 4.75777449e-03]\n",
      "cost for train data = 1.4428057924701554\n",
      "cost for test data = 2.718255659787015\n",
      "BIC: 509.4382826044525\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f01675-00a7-4997-a0f8-e70eb82c411c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79086fc8-3c5b-4603-8b7d-98675c4602f5",
   "metadata": {},
   "source": [
    "Remove 'lymph_node_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89c44174-9136-4712-8674-80c11aec7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.00036044760745601503 \t final weights = [3.75240851e-03 1.00411339e-05 2.12108869e-02 1.47490751e-05\n",
      " 3.52497827e-05 1.90647578e-05 4.81085717e-03]\n",
      "cost for train data = 1.5104632996841465\n",
      "cost for test data = 2.91331494650073\n",
      "BIC: 516.0831598998583\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cece84-9285-4bf6-bbf6-8b5d3fff7217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c24140fb-0bf9-4229-b878-858ced5de271",
   "metadata": {},
   "source": [
    "Remove 'worst_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1407e28e-9f4a-4925-ab11-1b2766853615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0003529006421880398 \t final weights = [3.69149248e-03 8.72943185e-06 2.08469828e-02 1.41942589e-05\n",
      " 1.86006752e-02 1.81474553e-05 4.75779045e-03]\n",
      "cost for train data = 1.4428056151342041\n",
      "cost for test data = 2.7182564907464397\n",
      "BIC: 509.4382647824319\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34880b-8353-422e-9a55-b7832590f6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a7c4587-fc5d-4d7a-8812-7cc3b80abe3c",
   "metadata": {},
   "source": [
    "Remove 'mean_fractal_dimension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40de7a15-b46c-418c-869b-81660a0a44d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0003528971985551293 \t final weights = [3.69148085e-03 8.72844361e-06 2.08469057e-02 3.31565099e-05\n",
      " 1.86006693e-02 1.81470174e-05 4.75777326e-03]\n",
      "cost for train data = 1.4428058052205013\n",
      "cost for test data = 2.7182555690100636\n",
      "BIC: 509.4382838858447\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_perimeter', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7380d-391d-4e13-b58a-e6316b25e093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b83885b-758c-403d-90a1-4ae12e23eeb1",
   "metadata": {},
   "source": [
    "Remove 'mean_perimeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5dceb90-3786-407b-958e-974ecea49a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0033757057638676546 \t final weights = [0.05832819 0.00059405 0.00020382 0.00099473 0.02553939 0.00033012\n",
      " 0.07058408]\n",
      "cost for train data = 1.408563974574644\n",
      "cost for test data = 2.734188425083715\n",
      "BIC: 505.955533822\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f414b-c0c9-4453-ad70-b308f820b7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf7ac325-8a88-4b28-b2b3-607d94e57aa0",
   "metadata": {},
   "source": [
    "Remove 'mean_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "313139a0-4b73-4c41-a15c-f5053c53bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.00035289779366688386 \t final weights = [3.69148179e-03 2.08469127e-02 1.41940088e-05 3.31568835e-05\n",
      " 1.86006705e-02 1.81471005e-05 4.75777392e-03]\n",
      "cost for train data = 1.4428057479852026\n",
      "cost for test data = 2.718255558331449\n",
      "BIC: 509.4382781337758\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc0769-9248-4be3-affb-da1b02dbca89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cae3b21-6cd4-4186-8019-4c077e809e1c",
   "metadata": {},
   "source": [
    "Remove 'mean_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1719c996-b9b8-47ef-a8cb-a0ea84746107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.00035770726814696966 \t final weights = [9.58228430e-06 2.13861730e-02 1.44730622e-05 3.45878450e-05\n",
      " 1.86128852e-02 1.86068878e-05 4.85758262e-03]\n",
      "cost for train data = 1.443136640878513\n",
      "cost for test data = 2.7179984747386183\n",
      "BIC: 509.47152860331073\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_symmetry', 'mean_perimeter', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0b1cc-2ebe-4aba-ad7a-a25911633701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90dd267f-82ed-4d1f-940b-8ab3b985c9fb",
   "metadata": {},
   "source": [
    "Since removing 'mean_perimeter' results in least BIC we are removing that feature from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b26fb6-a9fd-46f4-b561-8bdac3342674",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 6\n",
    "Forward step (add each of the 3 removed model and compare with 7 predictor model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922689cb-4e71-43f2-a969-df96cd19ad20",
   "metadata": {},
   "source": [
    "Add worst_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "caa798c1-027f-44cd-8079-fc4de27018a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -2.3052274482595947e+113 \t final weights = [-4.31877956e+114 -4.44013004e+112 -1.43005418e+112 -7.33580801e+112\n",
      " -5.72554267e+113 -2.36414011e+112 -5.33124310e+114 -3.93775084e+116]\n",
      "cost for train data = 1.9011902185278147e+239\n",
      "cost for test data = 1.565668062030281e+239\n",
      "BIC: 80345.52879354314\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'worst_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde361e8-60e7-401b-9806-f0b61c175dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58bb52c0-dfde-4675-8368-ce7ffbcf2d93",
   "metadata": {},
   "source": [
    "Add 'mean_area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302537a-7855-487f-99a9-c6d408c84844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a83806a7-b459-47a4-ab3d-edc4eac3cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = -9.653695090998901e+95 \t final weights = [-1.80211639e+97 -1.85973986e+95 -5.98731551e+94 -3.05431279e+95\n",
      " -2.40680766e+96 -9.90171542e+94 -2.19838223e+97 -1.07533719e+99]\n",
      "cost for train data = 6.296234428820404e+203\n",
      "cost for test data = 6.092829896001675e+203\n",
      "BIC: 68499.66799361396\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'mean_area', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6de3e99f-f93c-4288-8ab1-f36de476ef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0003528969713991515 \t final weights = [3.69147980e-03 8.72839265e-06 1.41939336e-05 3.31564123e-05\n",
      " 1.86006687e-02 1.81469889e-05 4.75777209e-03 2.08468986e-02]\n",
      "cost for train data = 1.4428057992878123\n",
      "cost for test data = 2.7182554659265104\n",
      "BIC: 509.43828328961763\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius','mean_perimeter', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89627b-5b88-4dba-8489-32fd0ab83e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffbf8737-212d-40f8-91b4-b2ee46fc2863",
   "metadata": {},
   "source": [
    "Since adding the removed features does not improve the BIC score we move on to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cdbccc-6149-4292-9713-944c27a621db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01810908-157c-45c7-85f8-57fb7bf6b822",
   "metadata": {},
   "source": [
    "Remove 'worst_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "06907282-0667-42d5-8b5b-b17fa2f1ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.006612322651295565 \t final weights = [0.11699446 0.00121862 0.00040633 0.00203407 0.03308894 0.00066308]\n",
      "cost for train data = 1.5063029561682175\n",
      "cost for test data = 3.07268172332279\n",
      "BIC: 515.6832282239659\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3e3aa-8336-4fe1-9dd8-2b496df29a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a751d8c3-52e9-437e-9caa-68c5672397eb",
   "metadata": {},
   "source": [
    "Remove 'mean_smoothness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c1c4b73-1006-420f-90b8-3862e0e37776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.006612322651295565 \t final weights = [0.11699446 0.00121862 0.00040633 0.00203407 0.03308894 0.00066308]\n",
      "cost for train data = 1.5063029561682175\n",
      "cost for test data = 3.07268172332279\n",
      "BIC: 515.6832282239659\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853942e6-6788-4234-a094-e6ac3c5fdf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f6bd6f-c91d-4a33-981e-4a8d541cc2fd",
   "metadata": {},
   "source": [
    "Remove 'lymph_node_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "809efe18-51ab-4efc-982b-19f90257df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.003446864918259788 \t final weights = [0.05949498 0.00060758 0.00020841 0.00101691 0.00033768 0.07196272]\n",
      "cost for train data = 1.500044495046233\n",
      "cost for test data = 3.0182876707422017\n",
      "BIC: 515.079520110834\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5016e-01af-40b0-9862-1903fa25fa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54df820f-41c3-4125-b86f-f9de9a666fad",
   "metadata": {},
   "source": [
    "Remove 'worst_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "447fcc8a-16f3-4800-9c37-9b6b6d792259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0033761207372361955 \t final weights = [0.05833476 0.00059414 0.00020385 0.02554033 0.00033017 0.07059208]\n",
      "cost for train data = 1.4085550700023655\n",
      "cost for test data = 2.7342372502039813\n",
      "BIC: 505.9546171671054\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcabfc-b675-4141-ba88-1ce62196241e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89943f42-20b6-49b2-afbb-960f8ecc78a9",
   "metadata": {},
   "source": [
    "Remove 'mean_fractal_dimension'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ec612c09-efaa-481c-8581-2db47d9f0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.003375722395664869 \t final weights = [0.05832845 0.00059405 0.00099474 0.02553943 0.00033013 0.0705844 ]\n",
      "cost for train data = 1.408563981556191\n",
      "cost for test data = 2.7341905932219173\n",
      "BIC: 505.95553454069244\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f55fd3-1184-40ff-9257-b9c92fb38aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975e943d-559e-4851-971b-680bac0cb994",
   "metadata": {},
   "source": [
    "Remove 'mean_symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a02dd13-d412-44ae-9867-7502c9af79be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0033758532217966087 \t final weights = [0.05833058 0.00020383 0.00099478 0.02553973 0.00033014 0.07058696]\n",
      "cost for train data = 1.4085600104240392\n",
      "cost for test data = 2.7342047800950255\n",
      "BIC: 505.9551257449393\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393bcc68-6716-4175-9763-46ee748cebee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5279eb1-3929-485d-bf09-3626171936b6",
   "metadata": {},
   "source": [
    "Remove 'mean_radius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "00d4061c-bea8-4114-96ef-aa50704a40af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.005144626213294888 \t final weights = [0.00093487 0.00031431 0.00155638 0.02973212 0.0005119  0.10914453]\n",
      "cost for train data = 1.4265219636087012\n",
      "cost for test data = 2.905855786304988\n",
      "BIC: 507.7924751297801\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21556a3-4c96-4bff-b02e-efa49150c66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1e3c8c-6f16-43a1-9afe-550fc2d6f2d7",
   "metadata": {},
   "source": [
    "Since none of the removal result in better model. I am going with 7 predictor model which includes features: 'mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724e721-b112-426b-98aa-7d864aaf2b14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 3 c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfd845-5354-4244-899d-f7c37d92cf8e",
   "metadata": {},
   "source": [
    "**model comparision**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12182a91-7b5a-47f4-aaa5-80c5271321fe",
   "metadata": {},
   "source": [
    "final model from backward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ed91e92-8187-4ab0-8605-b9305e895113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.003537260257371273 \t final weights = [0.05869724 0.00056853 0.00020645 0.00096274 0.04096097 0.00032939\n",
      " 0.07046306]\n",
      "cost for train data = 1.3604815492065987\n",
      "cost for test data = 2.5553141133176283\n",
      "BIC: 500.91939233055797\n"
     ]
    }
   ],
   "source": [
    "#the final column will be your target value when you use 'seperate_target(data) method\n",
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac9f11-2a84-4e39-ad52-6ec9e9d3afbb",
   "metadata": {},
   "source": [
    "Final model from forward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe561877-edf3-4927-b214-51644e6ffa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.007906412852465121 \t final weights = [0.13812438 0.05019468 0.0014123  0.00047995 0.00077893]\n",
      "cost for train data = 1.33702992151285\n",
      "cost for test data = 2.4930936537716972\n",
      "BIC: 498.39812654286203\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_fractal_dimension', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0f223-a8eb-4272-b2c2-04917e4209b7",
   "metadata": {},
   "source": [
    "From the comparision of BIC as well as cost the model obtained from forward stepwise regression is performing better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c6761-1ba4-42be-899e-b53ab4c96435",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 3 d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061e8df-980f-43b3-8eac-ae8d474edb81",
   "metadata": {},
   "source": [
    "Model from Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1573dd7b-c623-4a8f-918a-29d186902e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.012535865642508252 \t final weights = [0.09669292 0.15458462]\n",
      "cost for train data = 1.3228053271253322\n",
      "cost for test data = 1.831997478927214\n",
      "BIC: 496.8472140561521\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_texture', 'lymph_node_status', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e30b6-4bf4-45db-8a4f-5cfa6cdea68e",
   "metadata": {},
   "source": [
    "Model from Question 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3104824e-eee5-444d-98a4-b0f1541c1145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.007906412852465121 \t final weights = [0.13812438 0.05019468 0.0014123  0.00047995 0.00077893]\n",
      "cost for train data = 1.33702992151285\n",
      "cost for test data = 2.4930936537716972\n",
      "BIC: 498.39812654286203\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'lymph_node_status', 'mean_symmetry', 'mean_fractal_dimension', 'mean_smoothness', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab80dcc-1277-42d1-bb94-2a8f595c5962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d33e2-15ae-48e8-82e6-7d246d1bdf01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### a) Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c9a6c085-6da8-4461-8f6a-fb0e9aecec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "Iteration: 0\t Cost: 2.353\t Bias: 0.003\t Weight: [0.06 0.01]\n",
      "Iteration: 10\t Cost: 1.494\t Bias: 0.006\t Weight: [0.109 0.048]\n",
      "Iteration: 20\t Cost: 1.430\t Bias: 0.006\t Weight: [0.106 0.073]\n",
      "Iteration: 30\t Cost: 1.389\t Bias: 0.007\t Weight: [0.104 0.093]\n",
      "Iteration: 40\t Cost: 1.364\t Bias: 0.008\t Weight: [0.102 0.108]\n",
      "Iteration: 50\t Cost: 1.349\t Bias: 0.009\t Weight: [0.101 0.121]\n",
      "Iteration: 60\t Cost: 1.339\t Bias: 0.010\t Weight: [0.099 0.13 ]\n",
      "Iteration: 70\t Cost: 1.332\t Bias: 0.011\t Weight: [0.099 0.138]\n",
      "Iteration: 80\t Cost: 1.328\t Bias: 0.011\t Weight: [0.098 0.144]\n",
      "Iteration: 90\t Cost: 1.326\t Bias: 0.012\t Weight: [0.097 0.148]\n",
      "Iteration: 99\t Cost: 1.324\t Bias: 0.013\t Weight: [0.097 0.151]\n",
      "\n",
      "\n",
      "final bias = 0.012852630863148579 \t final weights = [0.09688136 0.15146141]\n",
      "cost for train data = 1.323995841745698\n",
      "cost for test data = 1.8416977312427831\n",
      "BIC: 496.9776542521326\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_texture', 'lymph_node_status', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "lam = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.regularized_gradient_descent(features, target, bias, weights, lam)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b0801-5e24-4cbe-ba7d-eda77bfef917",
   "metadata": {},
   "source": [
    "**not performing better than model of question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0be064-c8b9-4ffc-bded-3575e2512a0c",
   "metadata": {},
   "source": [
    "#### b) Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c56dc201-d516-4e3e-a6a7-404c16127ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "#first seperate columns by passing column names and after required columns are obtained from the data we split 80% of data as training data\n",
    "#index of the columns defined will be the same index on the array as well\n",
    "columns = ['mean_texture', 'lymph_node_status', 'tumor_size']#the final column will be the target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "\n",
    "# now seperate features and target as two seperate arrays with each features index corresponding to target index\n",
    "features, target = df.seperate_target(train_data)\n",
    "scaled_features = df.scale_features(features)\n",
    "\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "scaled_test_features = df.scale_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "02388515-1b42-4e71-a9a7-2cfbd6e1f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "final bias = 0.026331508580144967 \t final weights = [4.15278206e-05 1.38796268e-03]\n",
      "cost for train data = 4.972647652174251\n",
      "cost for test data = 8.629522301546837\n",
      "BIC: 688.8558799442048\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(scaled_features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(scaled_features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(scaled_features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(scaled_test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(scaled_features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671141d-a3a9-4e64-969d-9443d5aa6159",
   "metadata": {},
   "source": [
    "Feature scale even worsened the performance of the model from 3 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bda5b0-8f29-4caf-b8d2-9e067d483010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2318cb4-96c9-4eca-9f4d-1ec98377170d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extra test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa47cb-2e63-4b57-ad3f-90eb0959f7f0",
   "metadata": {},
   "source": [
    "Lets remove the extra features one by one that we ended up with while comparing to forward stepwise regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db928ec2-9115-4765-9db6-8645d8ed7f6c",
   "metadata": {},
   "source": [
    "remove worst_symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1e460add-5316-4d93-9ab2-0c3349b98a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.0033761207372361955 \t final weights = [0.05833476 0.00059414 0.00020385 0.02554033 0.00033017 0.07059208]\n",
      "cost for train data = 1.4085550700023655\n",
      "cost for test data = 2.7342372502039813\n",
      "BIC: 505.9546171671054\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'lymph_node_status', 'mean_smoothness', 'worst_radius', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 50\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc934b4e-53c5-412c-baac-68a5afd9fa49",
   "metadata": {},
   "source": [
    "Remove worst_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b1e24d3b-b8b4-4a2c-8ed6-ac1a893d4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n",
      "\n",
      "\n",
      "final bias = 0.007904191214125781 \t final weights = [0.13808835 0.00141185 0.0004798  0.00237189 0.05018994 0.0007787 ]\n",
      "cost for train data = 1.3370522151813151\n",
      "cost for test data = 2.492977379102992\n",
      "BIC: 498.4005442561275\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_symmetry', 'mean_fractal_dimension', 'worst_symmetry', 'lymph_node_status', 'mean_smoothness', 'tumor_size'] \n",
    "\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)\n",
    "\n",
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.0001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")\n",
    "\n",
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")\n",
    "\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "bic = calculate_bic(k, n, MSE_train)\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479003e-2637-4c05-b7cf-d54a6fd2b06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6734e13b-4d36-4d0d-ac75-a791aeb6413a",
   "metadata": {},
   "source": [
    "Still, the model from forward stepwise regression performs better than thhe model from backward stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e70b15-4c11-448f-a6c8-2aa06b52a575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
