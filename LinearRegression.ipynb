{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b51e95-4d54-4cac-8905-5e122b405880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c940ad-e5fb-4ef5-8443-1717301adbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManipulateData:\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def filter_data(self):\n",
    "        data = pd.read_csv(self.file).dropna()\n",
    "        data = data.sample(frac = 1) #shuffling\n",
    "        return data\n",
    "\n",
    "    def seperate_columns(self, data, columns):\n",
    "        data = data[columns]\n",
    "        return data\n",
    "    \n",
    "    def split_data(self, data, percent):\n",
    "        data_array = data.to_numpy()\n",
    "        np.random.shuffle(data_array)\n",
    "        train_size = math.floor(len(data_array)*percent)\n",
    "        train_data, test_data = data_array[:train_size,:], data_array[train_size:,:]\n",
    "        train_length = train_data.shape[0]\n",
    "        test_length = test_data.shape[0]\n",
    "        print(f\"total training rows: {train_length}\\ntotal testing rows: {test_length}\")\n",
    "        return train_data, test_data\n",
    "\n",
    "    def seperate_target(self, data):\n",
    "        rows = data.shape[0]\n",
    "        features = []\n",
    "        target = []\n",
    "        for row in range(rows):\n",
    "            features.append(data[row, :-1])\n",
    "            target.append(data[row, -1])\n",
    "        return np.array(features), np.array(target)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78f7920-450b-40c5-989c-72423342896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    # calculating cost using vectorization('np.dot()')\n",
    "    def calculate_cost(self, X_train, Y_train, th0, thj):\n",
    "            \n",
    "            m = X_train.shape[0]\n",
    "            \n",
    "            y_predict = th0 + np.dot(X_train, thj)\n",
    "            sq_difference = (y_predict - Y_train) ** 2\n",
    "            total_cost = np.sum(sq_difference) / (2*m)\n",
    "        \n",
    "            return total_cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aaad438-a8f2-4318-a0d7-34cf16afc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(MSE):\n",
    "    def __init__(self, alpha, iterations):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def calculate_gradient(self, X_train, Y_train, th0, thj):\n",
    "        m = X_train.shape[0]\n",
    "        \n",
    "        y_predict = th0 + np.dot(X_train, thj)\n",
    "\n",
    "        difference = y_predict - Y_train\n",
    "        \n",
    "        gradient_th0 = np.sum(difference) / m\n",
    "        gradient_thj = np.dot(difference, X_train) / m\n",
    "\n",
    "        return gradient_th0, gradient_thj\n",
    "    \n",
    "            \n",
    "    def gradient_descent(self, X_train, Y_train, th0, thj):\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            gradients = self.calculate_gradient(X_train, Y_train, th0, thj)\n",
    "            th0 = th0 - (self.alpha * gradients[0])\n",
    "            thj = thj - (self.alpha * gradients[1])\n",
    "\n",
    "            if i%10 == 0 or i == self.iterations - 1:\n",
    "                current_cost = self.calculate_cost(X_train, Y_train, th0, thj)\n",
    "                print(f\"Iteration: {i}\\t Cost: {current_cost:.3f}\\t Bias: {th0:.3f}\\t Weight: {np.round(thj, 3)}\")\n",
    "            \n",
    "        return th0, thj\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c027cdb-3f19-4195-b51e-e373d48af10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Cancer_dataset.csv'\n",
    "\n",
    "df = ManipulateData(file)\n",
    "data = df.filter_data() #cleans out rows containing null values and shuffles the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3efc42-796a-4042-8491-4707c669c795",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b8ab02-b794-47c0-a0ec-a90b12778f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_texture', 'tumor_size'] #the final column will be your target value when you use 'seperate_target(data) method\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1964b10-b2b8-4006-9c4a-048351d1792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 2.327\t Bias: 0.003\t Weight: [0.061]\n",
      "Iteration: 10\t Cost: 1.526\t Bias: 0.006\t Weight: [0.116]\n",
      "Iteration: 20\t Cost: 1.526\t Bias: 0.006\t Weight: [0.116]\n",
      "Iteration: 30\t Cost: 1.526\t Bias: 0.007\t Weight: [0.116]\n",
      "Iteration: 40\t Cost: 1.526\t Bias: 0.008\t Weight: [0.116]\n",
      "Iteration: 50\t Cost: 1.526\t Bias: 0.009\t Weight: [0.116]\n",
      "Iteration: 60\t Cost: 1.526\t Bias: 0.009\t Weight: [0.116]\n",
      "Iteration: 70\t Cost: 1.526\t Bias: 0.010\t Weight: [0.116]\n",
      "Iteration: 80\t Cost: 1.526\t Bias: 0.011\t Weight: [0.116]\n",
      "Iteration: 90\t Cost: 1.526\t Bias: 0.011\t Weight: [0.116]\n",
      "Iteration: 100\t Cost: 1.526\t Bias: 0.012\t Weight: [0.116]\n",
      "Iteration: 110\t Cost: 1.526\t Bias: 0.013\t Weight: [0.116]\n",
      "Iteration: 120\t Cost: 1.526\t Bias: 0.013\t Weight: [0.116]\n",
      "Iteration: 130\t Cost: 1.526\t Bias: 0.014\t Weight: [0.116]\n",
      "Iteration: 140\t Cost: 1.526\t Bias: 0.015\t Weight: [0.116]\n",
      "Iteration: 150\t Cost: 1.525\t Bias: 0.016\t Weight: [0.116]\n",
      "Iteration: 160\t Cost: 1.525\t Bias: 0.016\t Weight: [0.116]\n",
      "Iteration: 170\t Cost: 1.525\t Bias: 0.017\t Weight: [0.116]\n",
      "Iteration: 180\t Cost: 1.525\t Bias: 0.018\t Weight: [0.116]\n",
      "Iteration: 190\t Cost: 1.525\t Bias: 0.018\t Weight: [0.116]\n",
      "Iteration: 199\t Cost: 1.525\t Bias: 0.019\t Weight: [0.116]\n",
      "\n",
      "\n",
      "final bias = 0.01898922310947854 \t final weights = [0.11560586]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 200\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "# fit.calculate_gradient(features, target, bias, weights)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82e44fe-9a93-49b6-ad72-63ede8bf95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.5252175116261217\n",
      "cost for test data = 3.3619999842979245\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396a94c-e407-47a7-be6f-fe83c82bbddd",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5f49e7-7eba-4375-b6dd-4ef3842e0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_texture', 'lymph_node_status', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624d28a3-bba2-4076-9f08-69f2c8ad316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 2.981\t Bias: 0.003\t Weight: [0.068 0.015]\n",
      "Iteration: 10\t Cost: 1.812\t Bias: 0.006\t Weight: [0.12 0.07]\n",
      "Iteration: 20\t Cost: 1.686\t Bias: 0.007\t Weight: [0.115 0.105]\n",
      "Iteration: 30\t Cost: 1.613\t Bias: 0.007\t Weight: [0.111 0.132]\n",
      "Iteration: 40\t Cost: 1.571\t Bias: 0.008\t Weight: [0.108 0.152]\n",
      "Iteration: 50\t Cost: 1.547\t Bias: 0.009\t Weight: [0.106 0.168]\n",
      "Iteration: 60\t Cost: 1.533\t Bias: 0.010\t Weight: [0.104 0.18 ]\n",
      "Iteration: 70\t Cost: 1.525\t Bias: 0.010\t Weight: [0.103 0.188]\n",
      "Iteration: 80\t Cost: 1.520\t Bias: 0.011\t Weight: [0.102 0.195]\n",
      "Iteration: 90\t Cost: 1.517\t Bias: 0.012\t Weight: [0.101 0.2  ]\n",
      "Iteration: 99\t Cost: 1.516\t Bias: 0.013\t Weight: [0.1   0.204]\n",
      "\n",
      "\n",
      "final bias = 0.01263073395008496 \t final weights = [0.1002761  0.20394332]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883ecf31-ac1e-4b29-89e2-51e8c9329890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.5157785695611707\n",
      "cost for test data = 1.1074969966172434\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a54dfd-4bbf-4046-9ba3-f0e8bcb89659",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7498d-5443-4b09-8ecb-9c1ce69f2a78",
   "metadata": {},
   "source": [
    "#### Step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a149ee-28d2-4756-aa15-2386a45d34b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923d8a8b-aa58-4963-8c43-71454158ad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 4.063\t Bias: 0.003\t Weight: [0.053]\n",
      "Iteration: 10\t Cost: 1.999\t Bias: 0.010\t Weight: [0.164]\n",
      "Iteration: 20\t Cost: 1.998\t Bias: 0.010\t Weight: [0.167]\n",
      "Iteration: 30\t Cost: 1.998\t Bias: 0.010\t Weight: [0.167]\n",
      "Iteration: 40\t Cost: 1.998\t Bias: 0.011\t Weight: [0.167]\n",
      "Iteration: 50\t Cost: 1.998\t Bias: 0.011\t Weight: [0.167]\n",
      "Iteration: 60\t Cost: 1.998\t Bias: 0.012\t Weight: [0.167]\n",
      "Iteration: 70\t Cost: 1.998\t Bias: 0.012\t Weight: [0.167]\n",
      "Iteration: 80\t Cost: 1.998\t Bias: 0.012\t Weight: [0.167]\n",
      "Iteration: 90\t Cost: 1.998\t Bias: 0.013\t Weight: [0.167]\n",
      "Iteration: 99\t Cost: 1.998\t Bias: 0.013\t Weight: [0.167]\n",
      "\n",
      "\n",
      "final bias = 0.013037751461000552 \t final weights = [0.16667702]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8e54fa-c2f0-49f5-9283-46f0c4efc4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.99779128559342\n",
      "cost for test data = 0.9268725548302201\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fbe42-826a-42a4-86fb-4c52929c2ae9",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe2e5e4-8330-4da8-9efb-aff0b0938b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_smoothness', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6932740d-431a-447e-89c4-0bc2c644095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 3.597\t Bias: 0.003\t Weight: [0.05 0.  ]\n",
      "Iteration: 10\t Cost: 1.753\t Bias: 0.009\t Weight: [0.155 0.001]\n",
      "Iteration: 20\t Cost: 1.752\t Bias: 0.009\t Weight: [0.158 0.001]\n",
      "Iteration: 30\t Cost: 1.752\t Bias: 0.010\t Weight: [0.158 0.001]\n",
      "Iteration: 40\t Cost: 1.752\t Bias: 0.010\t Weight: [0.158 0.001]\n",
      "Iteration: 50\t Cost: 1.752\t Bias: 0.010\t Weight: [0.158 0.001]\n",
      "Iteration: 60\t Cost: 1.752\t Bias: 0.010\t Weight: [0.158 0.001]\n",
      "Iteration: 70\t Cost: 1.752\t Bias: 0.011\t Weight: [0.158 0.001]\n",
      "Iteration: 80\t Cost: 1.752\t Bias: 0.011\t Weight: [0.158 0.001]\n",
      "Iteration: 90\t Cost: 1.752\t Bias: 0.011\t Weight: [0.158 0.001]\n",
      "Iteration: 99\t Cost: 1.752\t Bias: 0.011\t Weight: [0.158 0.001]\n",
      "\n",
      "\n",
      "final bias = 0.011428564434892615 \t final weights = [0.15760473 0.00095352]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6551df-c95a-4753-bf42-65b0aca93f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.7523892144314996\n",
      "cost for test data = 1.8433812829175584\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b22ad0b-540b-4709-8a6c-7087c17e1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, adding 'mean_perimeter' feature to the model is not performing well to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "388ec4a1-6f7c-4df7-9063-472b5556c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rows: 145\n",
      "total testing rows: 37\n"
     ]
    }
   ],
   "source": [
    "columns = ['mean_radius', 'mean_smoothness', 'mean_symmetry', 'worst_radius', 'worst_symmetry', 'lymph_node_status', 'tumor_size'] #the final column will be your target column when you use 'seperate_target(data) method'\n",
    "sprtd_data = df.seperate_columns(data, columns)\n",
    "\n",
    "split_percent = 0.8\n",
    "train_data, test_data = df.split_data(sprtd_data, split_percent)\n",
    "features, target = df.seperate_target(train_data)\n",
    "test_features, test_target = df.seperate_target(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1163d50e-7466-496a-b5c9-1eb33f985839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Cost: 1.941\t Bias: 0.003\t Weight: [0.05  0.    0.001 0.061 0.001 0.016]\n",
      "Iteration: 10\t Cost: 1.569\t Bias: 0.004\t Weight: [0.06  0.    0.001 0.071 0.001 0.063]\n",
      "Iteration: 20\t Cost: 1.466\t Bias: 0.004\t Weight: [0.058 0.    0.001 0.068 0.001 0.095]\n",
      "Iteration: 30\t Cost: 1.414\t Bias: 0.004\t Weight: [0.057 0.    0.001 0.065 0.001 0.118]\n",
      "Iteration: 40\t Cost: 1.387\t Bias: 0.005\t Weight: [0.056 0.    0.001 0.063 0.001 0.134]\n",
      "Iteration: 50\t Cost: 1.373\t Bias: 0.005\t Weight: [0.055 0.    0.001 0.062 0.001 0.146]\n",
      "Iteration: 60\t Cost: 1.366\t Bias: 0.005\t Weight: [0.054 0.    0.001 0.061 0.001 0.154]\n",
      "Iteration: 70\t Cost: 1.362\t Bias: 0.006\t Weight: [0.054 0.    0.001 0.06  0.001 0.16 ]\n",
      "Iteration: 80\t Cost: 1.361\t Bias: 0.006\t Weight: [0.054 0.    0.001 0.06  0.001 0.164]\n",
      "Iteration: 90\t Cost: 1.360\t Bias: 0.006\t Weight: [0.054 0.    0.001 0.06  0.001 0.167]\n",
      "Iteration: 99\t Cost: 1.359\t Bias: 0.007\t Weight: [0.053 0.    0.001 0.059 0.001 0.169]\n",
      "\n",
      "\n",
      "final bias = 0.0067631143949097245 \t final weights = [0.05347046 0.00047915 0.00060173 0.05938683 0.00120663 0.16912948]\n"
     ]
    }
   ],
   "source": [
    "bias = 0\n",
    "weights = np.zeros(features.shape[1])\n",
    "learning_rate = 0.001\n",
    "iterations = 100\n",
    "fit = LinearRegression(learning_rate, iterations)\n",
    "prdtd_bias, prdtd_weights = fit.gradient_descent(features, target, bias, weights)\n",
    "print(f\"\\n\\nfinal bias = {prdtd_bias} \\t final weights = {prdtd_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc4ce9ee-a177-4ec1-a6dd-efaf06591738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost for train data = 1.3592339450001873\n",
      "cost for test data = 1.1680655736097192\n"
     ]
    }
   ],
   "source": [
    "mse = MSE()\n",
    "MSE_train = mse.calculate_cost(features, target, prdtd_bias, prdtd_weights)\n",
    "MSE_test = mse.calculate_cost(test_features, test_target, prdtd_bias, prdtd_weights)\n",
    "print(f\"cost for train data = {MSE_train}\\ncost for test data = {MSE_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fce89-465b-4865-b1b6-6e2b21513378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
